{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"illustration_gan.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"_iBazkTQQeoV","colab_type":"code","outputId":"e272e7b6-70fc-43bf-c263-1a18eeee02e7","executionInfo":{"status":"ok","timestamp":1555478446733,"user_tz":-480,"elapsed":23483,"user":{"displayName":"陈乐恒","photoUrl":"","userId":"14095346992415385481"}},"colab":{"base_uri":"https://localhost:8080/","height":199}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!nvcc --version"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2018 NVIDIA Corporation\n","Built on Sat_Aug_25_21:08:01_CDT_2018\n","Cuda compilation tools, release 10.0, V10.0.130\n"],"name":"stdout"}]},{"metadata":{"id":"AaFJYRlGQt_-","colab_type":"code","outputId":"6726fd41-21da-4e78-82dc-c11ec1b73957","executionInfo":{"status":"ok","timestamp":1555478460238,"user_tz":-480,"elapsed":36963,"user":{"displayName":"陈乐恒","photoUrl":"","userId":"14095346992415385481"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":147}},"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-bccd10cf-500b-4a27-a71b-633dc068b26e\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-bccd10cf-500b-4a27-a71b-633dc068b26e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving custom_layers.py to custom_layers.py\n","Saving dataset.py to dataset.py\n","Saving util.py to util.py\n"],"name":"stdout"}]},{"metadata":{"id":"05DwPf8jQywg","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","import custom_layers as op\n","import util\n","import dataset as dset"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YRRb6FjJRAew","colab_type":"code","colab":{}},"cell_type":"code","source":["class auxiliary_fc_net(nn.Module):\n","    def __init__(self, dim_noise, dim_filter, num_filter):\n","        super(auxiliary_fc_net, self).__init__()\n","\n","        fc_size = 1024\n","        inplace = True\n","        self.dim_imput = int((dim_filter ** 2) * num_filter)\n","        self.fc1 = nn.Linear(self.dim_imput, fc_size)\n","        self.relu1 = nn.ReLU(inplace=inplace)\n","        self.fc2 = nn.Linear(fc_size, fc_size)\n","        self.relu2 = nn.ReLU(inplace=inplace)\n","        self.fc3 = nn.Linear(fc_size, fc_size)\n","        self.relu3 = nn.ReLU(inplace=inplace)\n","        self.fc4 = nn.Linear(fc_size, dim_noise)\n","    \n","    def forward(self, x):\n","        x = self.relu1(self.fc1(x))\n","        x = self.relu2(self.fc2(x))\n","        x = self.relu3(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","\n","class generator_main(nn.Module):\n","\n","    def __init__(self, dim_noise, dim_filter, num_filter, dim_output_img=64, n_channel=3):\n","        super(generator_main, self).__init__()\n","\n","        inplace = True\n","        fc_size = 1024\n","        self.reshape_params = [-1,num_filter, dim_filter, dim_filter]\n","\n","        self.fc1 = nn.Linear(dim_noise, fc_size)\n","        self.relu_fc1 = nn.ReLU(inplace=inplace)\n","        self.fc2 = nn.Linear(fc_size, fc_size)\n","        self.relu_fc2 = nn.ReLU(inplace=inplace)\n","        self.fc3 = nn.Linear(fc_size, fc_size)\n","        self.relu_fc3 = nn.ReLU(inplace=inplace)\n","        self.fc4 = nn.Linear(fc_size, int((dim_filter ** 2) * num_filter))\n","        self.relu_fc4 = nn.ReLU(inplace=inplace)\n","\n","        self.bn_bilr_deconv1 = op.bn_bilinear_deconv2d(2, num_filter, dim_output_img * 8, 5, 1, 2)\n","        self.relu1 = nn.ReLU(inplace=inplace)\n","        self.bn_bilr_deconv2 = op.bn_bilinear_deconv2d(2, dim_output_img * 8, dim_output_img * 4, 5, 1, 2)\n","        self.relu2 = nn.ReLU(inplace=inplace)\n","        self.bn_bilr_deconv3 = op.bn_bilinear_deconv2d(2, dim_output_img * 4, dim_output_img * 2, 5, 1, 2)\n","        self.relu3 = nn.ReLU(inplace=inplace)\n","        self.bn_bilr_deconv4 = op.bn_bilinear_deconv2d(2, dim_output_img * 2, dim_output_img, 5, 1, 2)\n","        self.relu4 = nn.ReLU(inplace=inplace)\n","\n","        self.conv = nn.Conv2d(dim_output_img, n_channel, 5, 1, 2, bias=False)\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, x):\n","        x = self.relu_fc1(self.fc1(x))\n","        x = self.relu_fc2(self.fc2(x))\n","        x = self.relu_fc3(self.fc3(x))\n","        x = self.relu_fc4(self.fc4(x))\n","\n","        x_conv = x.view(self.reshape_params)\n","        x_conv = self.relu1(self.bn_bilr_deconv1(x_conv))\n","        x_conv = self.relu2(self.bn_bilr_deconv2(x_conv))\n","        x_conv = self.relu3(self.bn_bilr_deconv3(x_conv))\n","        x_conv = self.relu4(self.bn_bilr_deconv4(x_conv))\n","        x_conv = self.tanh(self.conv(x_conv))\n","\n","        return x_conv, x\n","\n","class generator(nn.Module):\n","\n","    def __init__(self, dim_noise=100, dim_output_img=64, n_channel=3):\n","        super(generator, self).__init__()\n","        num_reduce_half = 4\n","        dim_filter = int(dim_output_img / (2 ** num_reduce_half))\n","        self.gen_main = generator_main(dim_noise, dim_filter, dim_output_img * 16, dim_output_img, n_channel)\n","        self.auxiliary = auxiliary_fc_net(dim_noise, dim_filter, dim_output_img * 16)\n","\n","    def forward(self, x):\n","        x_data, x_fc = self.gen_main(x)\n","        x_id = self.auxiliary(x_fc)\n","        return x_data, x_id"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7_D3lpX7RNlj","colab_type":"code","colab":{}},"cell_type":"code","source":["class discriminator(nn.Module):\n","\n","    def __init__(self, dim_input_img=64, n_channel = 3):\n","        super(discriminator, self).__init__()\n","\n","        slope = 0.2\n","        proba = 0.5\n","        num_reduce_half = 4\n","        inplace = True\n","        \n","        self.conv1 = nn.Conv2d(n_channel, dim_input_img, 5, 1, 2, bias=False)\n","        self.lrelu1 = nn.LeakyReLU(negative_slope=slope, inplace=inplace)\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.do2 = nn.Dropout2d(p=proba, inplace=inplace)\n","        self.bn_conv2 = op.bn_conv2d(dim_input_img, dim_input_img * 2, 5, 1, 2)\n","        self.lrelu2 = nn.LeakyReLU(negative_slope=slope, inplace=inplace)\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n"," \n","        self.do3 = nn.Dropout2d(p=proba, inplace=inplace)\n","        self.bn_conv3 = op.bn_conv2d(dim_input_img * 2, dim_input_img * 4, 5, 1, 2)\n","        self.lrelu3 = nn.LeakyReLU(negative_slope=slope, inplace=inplace)\n","        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n"," \n","        self.do4 = nn.Dropout2d(p=proba, inplace=inplace)\n","        self.bn_conv4 = op.bn_conv2d(dim_input_img * 4, dim_input_img * 8, 5, 1, 2)\n","        self.lrelu4 = nn.LeakyReLU(negative_slope=slope, inplace=inplace)\n","        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        dim_output_feature = 100\n","        dim_c = 10\n","        dim_feature_map = int(dim_input_img / (2 ** num_reduce_half))\n","        self.flatten_size = dim_input_img * 8 * (dim_feature_map ** 2)\n","\n","        self.miniDis = op.minibatch_discrimination(self.flatten_size, dim_output_feature, dim_c)\n","\n","        fc_size = 1024\n","\n","        self.fc1 = nn.Linear(self.flatten_size, fc_size)\n","        self.lrelu_fc1 = nn.LeakyReLU(negative_slope=slope, inplace=inplace)\n","        self.fc2 = nn.Linear(fc_size, fc_size)\n","        self.lrelu_fc2 = nn.LeakyReLU(negative_slope=slope, inplace=inplace)\n","        self.fc3 = nn.Linear(fc_size, fc_size)\n","        self.lrelu_fc3 = nn.LeakyReLU(negative_slope=slope, inplace=inplace)\n","\n","        self.fc4 = nn.Linear(fc_size + dim_output_feature, 1)\n","        # self.fc4 = nn.Linear(fc_size + self.flatten_size + dim_output_feature, 1)\n","\n","    def forward(self, x):\n","        x = self.maxpool1(self.lrelu1(self.conv1(x)))\n","        x = self.bn_conv2(self.do2(x))\n","        x = self.maxpool2(self.lrelu2(x))\n","        x = self.bn_conv3(self.do3(x))\n","        x = self.maxpool3(self.lrelu3(x))\n","        x = self.bn_conv4(self.do4(x))\n","        x = self.maxpool4(self.lrelu4(x))\n","\n","        x = x.view(-1, self.flatten_size)\n","        x_mini_dis = self.miniDis(x)\n","\n","        x = self.lrelu_fc1(self.fc1(x))\n","        x = self.lrelu_fc2(self.fc2(x))\n","        x = self.lrelu_fc3(self.fc3(x))\n","        \n","        x = torch.cat([x, x_mini_dis], 1)\n","        x = self.fc4(x)\n","        \n","        return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m-MtTqBPRknN","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_base(epochs, batch_size, dim_noise, device, dataset, generator, discriminator, loss, loss_auxiliary, optimizer_gen, optimizer_dis, filepath=None):\n","    # load the data\n","    worker = 2\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=worker)\n","    \n","    # create the list to store each loss\n","    loss_list, score_list, img_list = [], [], []\n","    num_fixed_ns_img = 64\n","    fixed_noise = torch.randn(num_fixed_ns_img, dim_noise, device=device)\n","    test_img, _ = generator(fixed_noise)\n","    test_img = test_img.detach().cpu()\n","    img_list.append(test_img.numpy())\n","\n","    # start iterating the epoch\n","    for e in range(epochs):\n","        loss_dis, loss_gen, score_dis_real, score_dis_fake, score_gen = 0, 0, 0, 0, 0\n","\n","        for i, data in enumerate(dataloader):\n","            b_size = batch_size\n","            if len(data[0]) < batch_size:\n","                b_size = len(data[0])\n","            # ---------------------------\n","            # 1. Train the discriminator\n","            # ---------------------------\n","            # generate noise samples from the generator\n","            batch_noise = torch.randn(b_size, dim_noise, device=device)\n","            fake_data, noise_id = generator(batch_noise)\n","\n","            # start to train the discriminator\n","            discriminator.zero_grad()\n","            # calculate the loss of the noise samples, which assigns the same label 0\n","            # for all the samples, and get the single output(marks) from the discriminator\n","            output = discriminator(fake_data.detach()).view(-1) # use .detach() to stop the requirement of gradient\n","            label = torch.full((b_size,), 0, device=device)\n","            loss_d_ns = loss(output, label)\n","            loss_d_ns.backward()\n","            score_dis_fake = output.mean().item()\n","            \n","            # calculate the loss of the real samples and assigns label 1 to represent\n","            # all samples are true and get the single output(marks) from the discriminator\n","            read_data = data[0].to(device)\n","            output = discriminator(read_data).view(-1)\n","            label.fill_(1)\n","            loss_d_real = loss(output, label)\n","            loss_d_real.backward()\n","            score_dis_real = output.mean().item()\n","\n","            loss_d = loss_d_ns + loss_d_real\n","            loss_dis = loss_d.item()\n","            optimizer_dis.step()\n","\n","            # ---------------------------\n","            # 2. Train the generator\n","            # ---------------------------\n","            # Feed the noise samplea to the discriminator agian to geit the accurate scores\n","            # after training the discriminator, and assign label 1 not to see the noise as\n","            # real label but to let the loss function to be correct and do correct back propogation\n","            generator.zero_grad()            \n","            # batch_noise = Func.torch.randn(b_size, dim_noise)\n","            # fake_data = generator(batch_noise)\n","            output = discriminator(fake_data).view(-1)\n","            loss_main = loss(output, label)\n","            loss_aux = loss_auxiliary(noise_id, batch_noise)\n","            loss_g = loss_main + loss_aux\n","            loss_g.backward()\n","            score_gen = output.mean().item()\n","            loss_gen = loss_g.item()\n","            optimizer_gen.step()\n","\n","\n","            # print information to the console\n","            # print information 5 times in a epoch\n","            num2print = 30\n","            if (i + 1) % num2print == 0:\n","                print('epoch: %d, iter: %d, loss_D: %.4f, loss_G: %.4f;\\t Scores: train D: D(x): %.4f, D(G(z)): %.4f train G: D(G(z))： %.4f'\n","                        % (e, (i + 1), loss_dis, loss_gen, score_dis_real, score_dis_fake, score_gen))           \n","                \n","                # store the final loss for D and G for a specific time interval of a whole epoch\n","                loss_list.append([loss_dis, loss_gen])\n","                # store the final score from D for noise and real samples for a specific time imterval on current epoch\n","                score_list.append([score_dis_fake, score_dis_real, score_gen])\n","\n","        loss_list.append([loss_dis, loss_gen])\n","        score_list.append([score_dis_fake, score_dis_real, score_gen])\n","        # store the image that the generator create for each epoch\n","        test_img, _ = generator(fixed_noise)\n","        \n","        \"\"\"\n","        print(testx[0, 0])\n","        print(testx[1, 0])\n","        \n","        print(test_img[0, 0])\n","        print(test_img[1, 0])\n","        \"\"\"\n","        test_img = test_img.detach().cpu()\n","        img_list.append(test_img.numpy())\n","\n","        # save the model\n","        if (e + 1) % 5 == 0:\n","            util.save_checkpoint(e, generator, discriminator, filepath)\n","    \n","    loss_list = list(map(list, zip(*loss_list)))\n","    score_list = list(map(list, zip(*score_list)))\n","        \n","    return generator, discriminator, loss_list, score_list, img_list"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Not6G17mRq0b","colab_type":"code","colab":{}},"cell_type":"code","source":["def build_gen_dis(config):\n","    net_gen = generator(config.DIM_NOISE, config.DIM_IMG, config.N_CHANNEL).to(config.DEVICE)\n","    net_dis = discriminator(config.DIM_IMG, config.N_CHANNEL).to(config.DEVICE)\n","\n","    if config.INIT:\n","        net_gen.apply(init_weight)\n","        net_dis.apply(init_weight)\n","    else:\n","        ext = config.PATH_MODEL[-4]\n","        path_model = config.PATH_IMPORT_MODEL[:-4] + '_epoch_%d' + ext % config.IMPORT_IDX_EPOCH\n","        net_gen, net_dis = util.load_checkpoint(config.EPOCHS, net_gen, net_dis, path_model)\n","\n","    return net_gen, net_dis\n","\n","def train(dataset, net_gen, net_dis, config):\n","\n","    # config = config.config_illustration_gan\n","    # net_gen = generator(config.DIM_NOISE, config.DIM_IMG).to(config.DEVICE)\n","    # net_dis = discriminator(config.DIM_IMG).to(config.DEVICE)\n","\n","    loss_main = nn.BCEWithLogitsLoss()\n","    loss_aux = nn.MSELoss(size_average=True)\n","\n","    optim_gen = optim.Adam(net_gen.parameters(), lr=config.LEARNING_RATE, betas=(config.MOMENTUM, 0.99))\n","    optim_dis = optim.Adam(net_dis.parameters(), lr=config.LEARNING_RATE, betas=(config.MOMENTUM, 0.99))\n","\n","    net_gen, net_dis, losses, _, imgs = train_base(config.EPOCHS, config.BATCH_SIZE, config.DIM_NOISE, config.DEVICE,\n","                                                    dataset, net_gen, net_dis, loss_main, loss_aux, optim_gen, optim_dis, config.PATH_MODEL)\n","    \n","    return net_gen, net_dis, losses, imgs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3geqdQJoRW6N","colab_type":"code","colab":{}},"cell_type":"code","source":["def init_weight(layer):\n","    std = 0.02\n","    if type(layer) == nn.ConvTranspose2d:\n","        nn.init.normal_(layer.weight.data, mean=0, std=std)\n","    elif type(layer) == nn.Conv2d:\n","        nn.init.normal_(layer.weight.data, mean=0, std=std)\n","    elif type(layer) == nn.Linear:\n","        nn.init.normal_(layer.weight.data, mean=0, std=std)\n","        nn.init.normal_(layer.bias.data, mean=0, std=std)\n","    elif type(layer) == op.minibatch_discrimination:\n","        nn.init.normal_(layer.weight.data, mean=0, std=std)\n","        nn.init.constant_(layer.bias.data, 0)\n","    elif type(layer) == nn.BatchNorm2d:\n","        nn.init.normal_(layer.weight.data, mean=1, std=std)\n","        nn.init.constant_(layer.bias.data, 0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CXQbEoAtR5zG","colab_type":"code","colab":{}},"cell_type":"code","source":["PATH_IMAGE = '/content/gdrive/My Drive/data/image_64'\n","PATH_TAG = '/content/gdrive/My Drive/data/tags'\n","ARTWORK_TYPE = os.listdir(PATH_IMAGE)\n","IS_ADD_I2V_TAG = False\n","\n","class config_illustration_gan():\n","    PATH_MODEL = '/content/gdrive/My Drive/data/model/illust_gan_64.pth'\n","    IS_ADD_I2V_TAG = False\n","    BATCH_SIZE = 64\n","    DIM_IMG = 64\n","    DIM_NOISE = 100\n","    LEARNING_RATE = 0.0002\n","    MOMENTUM = 0.5\n","    EPOCHS = 10\n","    INIT = True\n","    IMPORT_IDX_EPOCH = EPOCHS\n","    DEVICE = torch.device(\"cuda:0\")\n","    N_CHANNEL = 3"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W7jPyXSLSHLJ","colab_type":"code","colab":{}},"cell_type":"code","source":["f_minst = dset.fmnist('content/gdrive/My Drive/data/Fashion-MNIST', download=True, image_size=config_illustration_gan.DIM_IMG)\n","\n","transform=transforms.Compose([transforms.Resize(64), transforms.ToTensor()])\n","anime = dset.animeFaceDataset('/content/gdrive/My Drive/data/anime-faces', transform=transform)\n","\n","dataset = dset.pokemonDataset(PATH_IMAGE, PATH_TAG, ARTWORK_TYPE, IS_ADD_I2V_TAG)\n","\n","\"\"\"\n","mean, std = get_channel_mean_std(dataset, DIM_IMG)\n","     \n","print(mean)\n","print(std)\n","\"\"\"\n","mean = [220.43362509, 217.50907014, 212.78514176]\n","std = [71.7985852,  73.64374336, 78.23258064]\n","transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean, std)])\n","dataset.set_transform(transform)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C44VUIqWorSq","colab_type":"code","outputId":"7d0aa183-b4e9-4f8d-a73e-d05885ccdbac","executionInfo":{"status":"error","timestamp":1555478675376,"user_tz":-480,"elapsed":252077,"user":{"displayName":"陈乐恒","photoUrl":"","userId":"14095346992415385481"}},"colab":{"base_uri":"https://localhost:8080/","height":8551}},"cell_type":"code","source":["CONFIG = config_illustration_gan\n","net_gen, net_dis = build_gen_dis(CONFIG)\n","print(net_gen)\n","print(net_dis)\n","net_gen, net_dis, losses, imgs = train(anime, net_gen, net_dis, CONFIG)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["generator(\n","  (gen_main): generator_main(\n","    (fc1): Linear(in_features=100, out_features=1024, bias=True)\n","    (relu_fc1): ReLU(inplace)\n","    (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","    (relu_fc2): ReLU(inplace)\n","    (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n","    (relu_fc3): ReLU(inplace)\n","    (fc4): Linear(in_features=1024, out_features=16384, bias=True)\n","    (relu_fc4): ReLU(inplace)\n","    (bn_bilr_deconv1): bn_bilinear_deconv2d(\n","      (bilinear): Upsample(scale_factor=2, mode=bilinear)\n","      (conv): Conv2d(1024, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (relu1): ReLU(inplace)\n","    (bn_bilr_deconv2): bn_bilinear_deconv2d(\n","      (bilinear): Upsample(scale_factor=2, mode=bilinear)\n","      (conv): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (relu2): ReLU(inplace)\n","    (bn_bilr_deconv3): bn_bilinear_deconv2d(\n","      (bilinear): Upsample(scale_factor=2, mode=bilinear)\n","      (conv): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (relu3): ReLU(inplace)\n","    (bn_bilr_deconv4): bn_bilinear_deconv2d(\n","      (bilinear): Upsample(scale_factor=2, mode=bilinear)\n","      (conv): Conv2d(128, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (relu4): ReLU(inplace)\n","    (conv): Conv2d(64, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","    (tanh): Tanh()\n","  )\n","  (auxiliary): auxiliary_fc_net(\n","    (fc1): Linear(in_features=16384, out_features=1024, bias=True)\n","    (relu1): ReLU(inplace)\n","    (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","    (relu2): ReLU(inplace)\n","    (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n","    (relu3): ReLU(inplace)\n","    (fc4): Linear(in_features=1024, out_features=100, bias=True)\n","  )\n",")\n","discriminator(\n","  (conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","  (lrelu1): LeakyReLU(negative_slope=0.2, inplace)\n","  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (do2): Dropout2d(p=0.5, inplace)\n","  (bn_conv2): bn_conv2d(\n","    (conv): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (lrelu2): LeakyReLU(negative_slope=0.2, inplace)\n","  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (do3): Dropout2d(p=0.5, inplace)\n","  (bn_conv3): bn_conv2d(\n","    (conv): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (lrelu3): LeakyReLU(negative_slope=0.2, inplace)\n","  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (do4): Dropout2d(p=0.5, inplace)\n","  (bn_conv4): bn_conv2d(\n","    (conv): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (lrelu4): LeakyReLU(negative_slope=0.2, inplace)\n","  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (miniDis): minibatch_discrimination()\n","  (fc1): Linear(in_features=8192, out_features=1024, bias=True)\n","  (lrelu_fc1): LeakyReLU(negative_slope=0.2, inplace)\n","  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","  (lrelu_fc2): LeakyReLU(negative_slope=0.2, inplace)\n","  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n","  (lrelu_fc3): LeakyReLU(negative_slope=0.2, inplace)\n","  (fc4): Linear(in_features=1124, out_features=1, bias=True)\n",")\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n","  warnings.warn(warning.format(ret))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n"],"name":"stderr"},{"output_type":"stream","text":["epoch: 0, iter: 30, loss_D: 1.3837, loss_G: 1.6936;\t Scores: train D: D(x): 0.0570, D(G(z)): 0.0472 train G: D(G(z))： -0.0038\n","epoch: 0, iter: 60, loss_D: 1.3559, loss_G: 1.7196;\t Scores: train D: D(x): 0.0510, D(G(z)): -0.0166 train G: D(G(z))： -0.0888\n","epoch: 0, iter: 90, loss_D: 1.3863, loss_G: 1.6562;\t Scores: train D: D(x): 0.0285, D(G(z)): 0.0227 train G: D(G(z))： -0.0129\n","epoch: 0, iter: 120, loss_D: 1.3754, loss_G: 1.6314;\t Scores: train D: D(x): -0.0509, D(G(z)): -0.0778 train G: D(G(z))： 0.0348\n","epoch: 0, iter: 150, loss_D: 1.3307, loss_G: 1.6716;\t Scores: train D: D(x): 0.1508, D(G(z)): 0.0290 train G: D(G(z))： -0.1375\n","epoch: 0, iter: 180, loss_D: 1.3755, loss_G: 1.6607;\t Scores: train D: D(x): 0.0060, D(G(z)): -0.0193 train G: D(G(z))： -0.1337\n","epoch: 0, iter: 210, loss_D: 1.3480, loss_G: 1.5974;\t Scores: train D: D(x): -0.0516, D(G(z)): -0.1368 train G: D(G(z))： -0.1121\n","epoch: 0, iter: 240, loss_D: 1.5667, loss_G: 1.6104;\t Scores: train D: D(x): 0.5377, D(G(z)): 0.6855 train G: D(G(z))： -0.2803\n","epoch: 0, iter: 270, loss_D: 0.2982, loss_G: 3.3499;\t Scores: train D: D(x): 2.4758, D(G(z)): -1.8837 train G: D(G(z))： -2.3804\n","epoch: 0, iter: 300, loss_D: 1.3958, loss_G: 1.8980;\t Scores: train D: D(x): -0.0964, D(G(z)): -0.3207 train G: D(G(z))： -0.6674\n","epoch: 0, iter: 330, loss_D: 1.1252, loss_G: 1.7700;\t Scores: train D: D(x): 0.1860, D(G(z)): -0.5067 train G: D(G(z))： -0.4878\n","epoch: 0, iter: 360, loss_D: 2.6495, loss_G: 2.9076;\t Scores: train D: D(x): -2.4841, D(G(z)): -3.2304 train G: D(G(z))： -2.0068\n","epoch: 0, iter: 390, loss_D: 1.3126, loss_G: 1.5984;\t Scores: train D: D(x): 0.1865, D(G(z)): -0.0537 train G: D(G(z))： -0.3372\n","epoch: 0, iter: 420, loss_D: 1.1381, loss_G: 1.4595;\t Scores: train D: D(x): 0.4538, D(G(z)): -0.3686 train G: D(G(z))： -0.0144\n","epoch: 0, iter: 450, loss_D: 1.2086, loss_G: 1.8440;\t Scores: train D: D(x): 0.0639, D(G(z)): -0.4678 train G: D(G(z))： -0.6953\n","epoch: 0, iter: 480, loss_D: 1.3398, loss_G: 1.5322;\t Scores: train D: D(x): 0.0489, D(G(z)): -0.0538 train G: D(G(z))： -0.2880\n","epoch: 0, iter: 510, loss_D: 1.1599, loss_G: 1.5637;\t Scores: train D: D(x): 0.2805, D(G(z)): -0.2367 train G: D(G(z))： -0.3231\n","epoch: 0, iter: 540, loss_D: 1.1726, loss_G: 1.6154;\t Scores: train D: D(x): -0.3349, D(G(z)): -1.2003 train G: D(G(z))： -0.4391\n","epoch: 0, iter: 570, loss_D: 1.1619, loss_G: 1.2613;\t Scores: train D: D(x): 0.0284, D(G(z)): -0.5768 train G: D(G(z))： 0.2396\n","epoch: 0, iter: 600, loss_D: 1.2892, loss_G: 1.5389;\t Scores: train D: D(x): 0.1031, D(G(z)): -0.1583 train G: D(G(z))： -0.3801\n","epoch: 0, iter: 630, loss_D: 1.4044, loss_G: 1.3665;\t Scores: train D: D(x): -0.7086, D(G(z)): -1.1418 train G: D(G(z))： 0.0524\n","epoch: 0, iter: 660, loss_D: 1.0018, loss_G: 1.3347;\t Scores: train D: D(x): 0.2136, D(G(z)): -0.8318 train G: D(G(z))： 0.0513\n","epoch: 0, iter: 690, loss_D: 1.6477, loss_G: 1.4080;\t Scores: train D: D(x): -0.7859, D(G(z)): -0.5562 train G: D(G(z))： -0.1357\n","epoch: 0, iter: 720, loss_D: 1.1915, loss_G: 1.3638;\t Scores: train D: D(x): -0.0742, D(G(z)): -0.6434 train G: D(G(z))： -0.0210\n","epoch: 0, iter: 750, loss_D: 1.3265, loss_G: 2.2675;\t Scores: train D: D(x): 0.1581, D(G(z)): -0.1424 train G: D(G(z))： -1.4158\n","epoch: 0, iter: 780, loss_D: 1.4493, loss_G: 1.3901;\t Scores: train D: D(x): -0.5132, D(G(z)): -0.5628 train G: D(G(z))： -0.0657\n","epoch: 0, iter: 810, loss_D: 1.4329, loss_G: 1.3047;\t Scores: train D: D(x): -0.0489, D(G(z)): 0.0186 train G: D(G(z))： -0.0508\n","epoch: 0, iter: 840, loss_D: 1.2604, loss_G: 1.4111;\t Scores: train D: D(x): -0.1071, D(G(z)): -0.4588 train G: D(G(z))： -0.2603\n","epoch: 0, iter: 870, loss_D: 1.3516, loss_G: 0.7822;\t Scores: train D: D(x): -0.5719, D(G(z)): -1.1784 train G: D(G(z))： 1.4061\n","epoch: 0, iter: 900, loss_D: 1.2966, loss_G: 1.1887;\t Scores: train D: D(x): 0.0555, D(G(z)): -0.1493 train G: D(G(z))： 0.0500\n","epoch: 0, iter: 930, loss_D: 1.3706, loss_G: 1.2077;\t Scores: train D: D(x): -0.1923, D(G(z)): -0.2818 train G: D(G(z))： -0.0166\n","epoch: 0, iter: 960, loss_D: 1.3728, loss_G: 1.3313;\t Scores: train D: D(x): 0.0037, D(G(z)): -0.0567 train G: D(G(z))： -0.1943\n","epoch: 0, iter: 990, loss_D: 1.3132, loss_G: 1.1787;\t Scores: train D: D(x): 0.1040, D(G(z)): -0.0747 train G: D(G(z))： 0.0570\n","epoch: 0, iter: 1020, loss_D: 1.3583, loss_G: 1.2373;\t Scores: train D: D(x): -0.1765, D(G(z)): -0.2690 train G: D(G(z))： -0.0190\n","epoch: 0, iter: 1050, loss_D: 1.3991, loss_G: 1.2676;\t Scores: train D: D(x): -0.2379, D(G(z)): -0.2527 train G: D(G(z))： -0.1443\n","epoch: 0, iter: 1080, loss_D: 1.2898, loss_G: 1.2960;\t Scores: train D: D(x): 0.2063, D(G(z)): -0.0109 train G: D(G(z))： -0.3068\n","epoch: 0, iter: 1110, loss_D: 1.4167, loss_G: 1.1939;\t Scores: train D: D(x): 0.1163, D(G(z)): 0.1502 train G: D(G(z))： -0.0743\n","epoch: 0, iter: 1140, loss_D: 1.2811, loss_G: 1.4916;\t Scores: train D: D(x): -0.1492, D(G(z)): -0.4198 train G: D(G(z))： -0.5437\n","epoch: 0, iter: 1170, loss_D: 1.3636, loss_G: 2.6275;\t Scores: train D: D(x): 0.1961, D(G(z)): -0.0812 train G: D(G(z))： -1.9753\n","epoch: 0, iter: 1200, loss_D: 1.3418, loss_G: 1.3974;\t Scores: train D: D(x): -0.2368, D(G(z)): -0.4888 train G: D(G(z))： -0.3236\n","epoch: 0, iter: 1230, loss_D: 1.3826, loss_G: 1.1089;\t Scores: train D: D(x): -0.1619, D(G(z)): -0.2754 train G: D(G(z))： 0.0563\n","epoch: 0, iter: 1260, loss_D: 1.1091, loss_G: 2.2286;\t Scores: train D: D(x): 0.4064, D(G(z)): -0.3192 train G: D(G(z))： -1.5530\n","epoch: 0, iter: 1290, loss_D: 1.1651, loss_G: 0.9809;\t Scores: train D: D(x): 0.0965, D(G(z)): -0.4562 train G: D(G(z))： 0.4892\n","epoch: 0, iter: 1320, loss_D: 1.2940, loss_G: 1.2108;\t Scores: train D: D(x): 0.2101, D(G(z)): -0.0084 train G: D(G(z))： -0.2284\n","epoch: 1, iter: 30, loss_D: 1.2749, loss_G: 1.1346;\t Scores: train D: D(x): 0.0007, D(G(z)): -0.2583 train G: D(G(z))： -0.0772\n","epoch: 1, iter: 60, loss_D: 1.5360, loss_G: 1.2237;\t Scores: train D: D(x): -0.0174, D(G(z)): 0.2205 train G: D(G(z))： -0.2267\n","epoch: 1, iter: 90, loss_D: 1.3544, loss_G: 1.2790;\t Scores: train D: D(x): -0.0612, D(G(z)): -0.1499 train G: D(G(z))： -0.3332\n","epoch: 1, iter: 120, loss_D: 1.4760, loss_G: 1.1241;\t Scores: train D: D(x): -0.0976, D(G(z)): 0.0679 train G: D(G(z))： 0.0107\n","epoch: 1, iter: 150, loss_D: 1.3697, loss_G: 1.2202;\t Scores: train D: D(x): 0.0276, D(G(z)): -0.0602 train G: D(G(z))： -0.1508\n","epoch: 1, iter: 180, loss_D: 1.3984, loss_G: 1.9571;\t Scores: train D: D(x): 1.1049, D(G(z)): 0.6355 train G: D(G(z))： -1.3357\n","epoch: 1, iter: 210, loss_D: 1.0239, loss_G: 1.8935;\t Scores: train D: D(x): 1.0026, D(G(z)): -0.0750 train G: D(G(z))： -1.1605\n","epoch: 1, iter: 240, loss_D: 1.3412, loss_G: 1.5067;\t Scores: train D: D(x): -0.0709, D(G(z)): -0.2090 train G: D(G(z))： -0.6699\n","epoch: 1, iter: 270, loss_D: 1.2817, loss_G: 1.1492;\t Scores: train D: D(x): 0.1047, D(G(z)): -0.1418 train G: D(G(z))： -0.1383\n","epoch: 1, iter: 300, loss_D: 1.2888, loss_G: 1.2005;\t Scores: train D: D(x): 0.1062, D(G(z)): -0.1221 train G: D(G(z))： -0.2091\n","epoch: 1, iter: 330, loss_D: 1.2567, loss_G: 1.3194;\t Scores: train D: D(x): 0.2319, D(G(z)): -0.2212 train G: D(G(z))： -0.4130\n","epoch: 1, iter: 360, loss_D: 1.3852, loss_G: 1.0652;\t Scores: train D: D(x): 0.2575, D(G(z)): 0.2047 train G: D(G(z))： 0.0346\n","epoch: 1, iter: 390, loss_D: 1.7536, loss_G: 1.2653;\t Scores: train D: D(x): -0.6777, D(G(z)): -0.1097 train G: D(G(z))： -0.3298\n","epoch: 1, iter: 420, loss_D: 1.3226, loss_G: 1.2265;\t Scores: train D: D(x): 0.1154, D(G(z)): -0.0820 train G: D(G(z))： -0.3511\n","epoch: 1, iter: 450, loss_D: 1.3049, loss_G: 1.4502;\t Scores: train D: D(x): -0.0881, D(G(z)): -0.3575 train G: D(G(z))： -0.6669\n","epoch: 1, iter: 480, loss_D: 1.3197, loss_G: 1.1793;\t Scores: train D: D(x): -0.1003, D(G(z)): -0.2825 train G: D(G(z))： -0.2677\n","epoch: 1, iter: 510, loss_D: 1.4200, loss_G: 1.3940;\t Scores: train D: D(x): 0.1687, D(G(z)): 0.1251 train G: D(G(z))： -0.5408\n","epoch: 1, iter: 540, loss_D: 1.2814, loss_G: 1.1672;\t Scores: train D: D(x): -0.0404, D(G(z)): -0.3312 train G: D(G(z))： -0.1779\n","epoch: 1, iter: 570, loss_D: 1.0272, loss_G: 1.0404;\t Scores: train D: D(x): 0.3013, D(G(z)): -0.5654 train G: D(G(z))： 0.1018\n","epoch: 1, iter: 600, loss_D: 1.9023, loss_G: 1.0248;\t Scores: train D: D(x): -1.1848, D(G(z)): -0.7712 train G: D(G(z))： 0.1160\n","epoch: 1, iter: 630, loss_D: 1.4432, loss_G: 1.7697;\t Scores: train D: D(x): -0.8338, D(G(z)): -1.3292 train G: D(G(z))： -1.1115\n","epoch: 1, iter: 660, loss_D: 1.3682, loss_G: 1.2769;\t Scores: train D: D(x): -0.2688, D(G(z)): -0.4927 train G: D(G(z))： -0.3880\n","epoch: 1, iter: 690, loss_D: 1.1003, loss_G: 1.8401;\t Scores: train D: D(x): 0.0058, D(G(z)): -0.9137 train G: D(G(z))： -1.1477\n","epoch: 1, iter: 720, loss_D: 1.3328, loss_G: 1.7746;\t Scores: train D: D(x): -0.2914, D(G(z)): -0.7165 train G: D(G(z))： -0.9662\n","epoch: 1, iter: 750, loss_D: 2.3125, loss_G: 1.6848;\t Scores: train D: D(x): -2.0418, D(G(z)): -2.4503 train G: D(G(z))： -0.9227\n","epoch: 1, iter: 780, loss_D: 1.3101, loss_G: 1.4678;\t Scores: train D: D(x): -0.6605, D(G(z)): -1.6065 train G: D(G(z))： -0.6108\n","epoch: 1, iter: 810, loss_D: 1.0757, loss_G: 1.3336;\t Scores: train D: D(x): 0.5122, D(G(z)): -0.2658 train G: D(G(z))： -0.4901\n","epoch: 1, iter: 840, loss_D: 1.4438, loss_G: 1.0859;\t Scores: train D: D(x): 0.1410, D(G(z)): 0.1429 train G: D(G(z))： -0.1096\n","epoch: 1, iter: 870, loss_D: 1.2703, loss_G: 0.9624;\t Scores: train D: D(x): 0.5294, D(G(z)): 0.0247 train G: D(G(z))： 0.3254\n","epoch: 1, iter: 900, loss_D: 1.5433, loss_G: 1.2617;\t Scores: train D: D(x): -0.1049, D(G(z)): 0.1030 train G: D(G(z))： -0.4178\n","epoch: 1, iter: 930, loss_D: 1.2561, loss_G: 1.2966;\t Scores: train D: D(x): 0.0484, D(G(z)): -0.3257 train G: D(G(z))： -0.4206\n","epoch: 1, iter: 960, loss_D: 1.4444, loss_G: 1.3902;\t Scores: train D: D(x): -0.1642, D(G(z)): -0.1282 train G: D(G(z))： -0.6177\n","epoch: 1, iter: 990, loss_D: 1.2842, loss_G: 1.0789;\t Scores: train D: D(x): 0.1427, D(G(z)): -0.1077 train G: D(G(z))： -0.1286\n","epoch: 1, iter: 1020, loss_D: 1.3532, loss_G: 1.2374;\t Scores: train D: D(x): -0.0528, D(G(z)): -0.1755 train G: D(G(z))： -0.3954\n","epoch: 1, iter: 1050, loss_D: 1.0794, loss_G: 0.9376;\t Scores: train D: D(x): 0.2193, D(G(z)): -0.6496 train G: D(G(z))： 0.2021\n","epoch: 1, iter: 1080, loss_D: 1.2639, loss_G: 1.3134;\t Scores: train D: D(x): -0.2993, D(G(z)): -0.8136 train G: D(G(z))： -0.4579\n","epoch: 1, iter: 1110, loss_D: 0.9258, loss_G: 1.6393;\t Scores: train D: D(x): 0.6833, D(G(z)): -0.5866 train G: D(G(z))： -0.9670\n","epoch: 1, iter: 1140, loss_D: 1.1342, loss_G: 1.8635;\t Scores: train D: D(x): 0.3266, D(G(z)): -0.4425 train G: D(G(z))： -1.0157\n","epoch: 1, iter: 1170, loss_D: 1.5063, loss_G: 1.2244;\t Scores: train D: D(x): -0.4790, D(G(z)): -0.4845 train G: D(G(z))： -0.2938\n","epoch: 1, iter: 1200, loss_D: 1.4350, loss_G: 1.2369;\t Scores: train D: D(x): -0.1813, D(G(z)): -0.3014 train G: D(G(z))： -0.4096\n","epoch: 1, iter: 1230, loss_D: 0.9555, loss_G: 0.6496;\t Scores: train D: D(x): 0.3129, D(G(z)): -0.9156 train G: D(G(z))： 0.9075\n","epoch: 1, iter: 1260, loss_D: 1.0925, loss_G: 1.3708;\t Scores: train D: D(x): 0.0557, D(G(z)): -0.9456 train G: D(G(z))： -0.5352\n","epoch: 1, iter: 1290, loss_D: 1.2279, loss_G: 1.7377;\t Scores: train D: D(x): -0.3278, D(G(z)): -1.1358 train G: D(G(z))： -1.1432\n","epoch: 1, iter: 1320, loss_D: 1.4931, loss_G: 2.5552;\t Scores: train D: D(x): 1.0605, D(G(z)): 0.6975 train G: D(G(z))： -2.0376\n","epoch: 2, iter: 30, loss_D: 1.0014, loss_G: 1.8851;\t Scores: train D: D(x): 1.0226, D(G(z)): -0.1395 train G: D(G(z))： -1.2544\n","epoch: 2, iter: 60, loss_D: 1.4444, loss_G: 1.6103;\t Scores: train D: D(x): 0.4960, D(G(z)): 0.3863 train G: D(G(z))： -0.9566\n","epoch: 2, iter: 90, loss_D: 1.0818, loss_G: 1.0295;\t Scores: train D: D(x): 0.2056, D(G(z)): -0.7209 train G: D(G(z))： 0.0933\n","epoch: 2, iter: 120, loss_D: 1.2577, loss_G: 1.2253;\t Scores: train D: D(x): 0.5213, D(G(z)): 0.0267 train G: D(G(z))： -0.3058\n","epoch: 2, iter: 150, loss_D: 1.1305, loss_G: 1.2474;\t Scores: train D: D(x): 1.2992, D(G(z)): 0.2354 train G: D(G(z))： -0.4151\n","epoch: 2, iter: 180, loss_D: 1.4252, loss_G: 1.6248;\t Scores: train D: D(x): 0.6967, D(G(z)): 0.4877 train G: D(G(z))： -0.9655\n","epoch: 2, iter: 210, loss_D: 0.9218, loss_G: 1.4839;\t Scores: train D: D(x): 0.4867, D(G(z)): -0.8521 train G: D(G(z))： -0.6986\n","epoch: 2, iter: 240, loss_D: 1.2018, loss_G: 1.4726;\t Scores: train D: D(x): 0.2472, D(G(z)): -0.4889 train G: D(G(z))： -0.7307\n","epoch: 2, iter: 270, loss_D: 1.1944, loss_G: 1.7720;\t Scores: train D: D(x): 0.3791, D(G(z)): -0.1983 train G: D(G(z))： -1.1640\n","epoch: 2, iter: 300, loss_D: 0.8199, loss_G: 1.4380;\t Scores: train D: D(x): 0.4708, D(G(z)): -1.0656 train G: D(G(z))： -0.6644\n","epoch: 2, iter: 330, loss_D: 1.2326, loss_G: 1.4072;\t Scores: train D: D(x): 0.0730, D(G(z)): -0.4189 train G: D(G(z))： -0.6710\n","epoch: 2, iter: 360, loss_D: 1.2769, loss_G: 1.2377;\t Scores: train D: D(x): -0.0395, D(G(z)): -0.6012 train G: D(G(z))： -0.2964\n","epoch: 2, iter: 390, loss_D: 0.9148, loss_G: 1.9679;\t Scores: train D: D(x): 0.3191, D(G(z)): -1.1434 train G: D(G(z))： -1.3403\n","epoch: 2, iter: 420, loss_D: 1.1864, loss_G: 3.2813;\t Scores: train D: D(x): 3.6262, D(G(z)): 0.5726 train G: D(G(z))： -2.7261\n","epoch: 2, iter: 450, loss_D: 0.7816, loss_G: 2.4540;\t Scores: train D: D(x): 0.7579, D(G(z)): -1.1323 train G: D(G(z))： -2.0234\n","epoch: 2, iter: 480, loss_D: 1.1408, loss_G: 1.1360;\t Scores: train D: D(x): 0.0238, D(G(z)): -0.9015 train G: D(G(z))： -0.2122\n","epoch: 2, iter: 510, loss_D: 1.0889, loss_G: 2.0576;\t Scores: train D: D(x): 0.9942, D(G(z)): -0.0330 train G: D(G(z))： -1.5535\n","epoch: 2, iter: 540, loss_D: 0.9728, loss_G: 1.9887;\t Scores: train D: D(x): 0.7213, D(G(z)): -0.5491 train G: D(G(z))： -1.4670\n","epoch: 2, iter: 570, loss_D: 1.1201, loss_G: 1.4797;\t Scores: train D: D(x): 1.3223, D(G(z)): 0.1703 train G: D(G(z))： -0.7196\n","epoch: 2, iter: 600, loss_D: 0.8997, loss_G: 1.1656;\t Scores: train D: D(x): 0.8013, D(G(z)): -0.6652 train G: D(G(z))： -0.2048\n","epoch: 2, iter: 630, loss_D: 1.2819, loss_G: 1.3717;\t Scores: train D: D(x): 1.6317, D(G(z)): 0.5207 train G: D(G(z))： -0.5981\n","epoch: 2, iter: 660, loss_D: 1.4564, loss_G: 1.8146;\t Scores: train D: D(x): -0.7262, D(G(z)): -1.1304 train G: D(G(z))： -1.2364\n","epoch: 2, iter: 690, loss_D: 1.0684, loss_G: 1.9243;\t Scores: train D: D(x): 0.1495, D(G(z)): -1.1814 train G: D(G(z))： -1.2795\n","epoch: 2, iter: 720, loss_D: 1.2301, loss_G: 2.0104;\t Scores: train D: D(x): 0.4453, D(G(z)): -0.0980 train G: D(G(z))： -1.3329\n","epoch: 2, iter: 750, loss_D: 0.8992, loss_G: 1.3326;\t Scores: train D: D(x): 1.4244, D(G(z)): -0.1838 train G: D(G(z))： -0.5223\n","epoch: 2, iter: 780, loss_D: 1.0304, loss_G: 1.3578;\t Scores: train D: D(x): 0.6429, D(G(z)): -0.3733 train G: D(G(z))： -0.5416\n","epoch: 2, iter: 810, loss_D: 0.6811, loss_G: 1.8680;\t Scores: train D: D(x): 1.6903, D(G(z)): -0.7718 train G: D(G(z))： -1.2049\n","epoch: 2, iter: 840, loss_D: 1.4994, loss_G: 3.1700;\t Scores: train D: D(x): -0.7444, D(G(z)): -1.2808 train G: D(G(z))： -2.8066\n","epoch: 2, iter: 870, loss_D: 0.9814, loss_G: 0.7548;\t Scores: train D: D(x): 1.2994, D(G(z)): -0.1371 train G: D(G(z))： 0.7211\n","epoch: 2, iter: 900, loss_D: 1.2871, loss_G: 1.9392;\t Scores: train D: D(x): 1.1624, D(G(z)): 0.3544 train G: D(G(z))： -1.3020\n","epoch: 2, iter: 930, loss_D: 1.3355, loss_G: 1.4720;\t Scores: train D: D(x): -0.1340, D(G(z)): -0.5031 train G: D(G(z))： -0.7262\n","epoch: 2, iter: 960, loss_D: 1.2153, loss_G: 1.3930;\t Scores: train D: D(x): 0.0642, D(G(z)): -0.5572 train G: D(G(z))： -0.5602\n","epoch: 2, iter: 990, loss_D: 1.0470, loss_G: 1.2235;\t Scores: train D: D(x): 0.2146, D(G(z)): -0.8992 train G: D(G(z))： -0.3873\n","epoch: 2, iter: 1020, loss_D: 0.6856, loss_G: 0.9488;\t Scores: train D: D(x): 1.3030, D(G(z)): -0.7995 train G: D(G(z))： 0.3320\n","epoch: 2, iter: 1050, loss_D: 0.5912, loss_G: 1.1081;\t Scores: train D: D(x): 1.2660, D(G(z)): -1.3701 train G: D(G(z))： -0.0769\n","epoch: 2, iter: 1080, loss_D: 0.8005, loss_G: 1.7560;\t Scores: train D: D(x): 0.6333, D(G(z)): -1.3043 train G: D(G(z))： -1.0473\n","epoch: 2, iter: 1110, loss_D: 1.0324, loss_G: 0.6865;\t Scores: train D: D(x): -0.0360, D(G(z)): -1.4046 train G: D(G(z))： 0.7844\n","epoch: 2, iter: 1140, loss_D: 1.3419, loss_G: 1.5890;\t Scores: train D: D(x): 0.4571, D(G(z)): 0.1104 train G: D(G(z))： -0.9529\n","epoch: 2, iter: 1170, loss_D: 1.2861, loss_G: 1.3329;\t Scores: train D: D(x): 1.0281, D(G(z)): 0.3415 train G: D(G(z))： -0.4724\n","epoch: 2, iter: 1200, loss_D: 1.4013, loss_G: 1.9122;\t Scores: train D: D(x): -0.0207, D(G(z)): -0.1788 train G: D(G(z))： -1.3446\n","epoch: 2, iter: 1230, loss_D: 0.9276, loss_G: 1.5144;\t Scores: train D: D(x): 0.5595, D(G(z)): -0.8001 train G: D(G(z))： -0.7575\n","epoch: 2, iter: 1260, loss_D: 1.0126, loss_G: 1.6383;\t Scores: train D: D(x): 0.7365, D(G(z)): -0.3806 train G: D(G(z))： -0.8689\n","epoch: 2, iter: 1290, loss_D: 0.8466, loss_G: 2.6495;\t Scores: train D: D(x): 2.3730, D(G(z)): -0.1836 train G: D(G(z))： -2.2373\n","epoch: 2, iter: 1320, loss_D: 0.5467, loss_G: 1.7450;\t Scores: train D: D(x): 0.8511, D(G(z)): -2.3074 train G: D(G(z))： -1.0494\n","epoch: 3, iter: 30, loss_D: 0.8267, loss_G: 2.8810;\t Scores: train D: D(x): 0.1221, D(G(z)): -2.9772 train G: D(G(z))： -2.3947\n","epoch: 3, iter: 60, loss_D: 0.9989, loss_G: 2.2956;\t Scores: train D: D(x): 1.1797, D(G(z)): -0.3270 train G: D(G(z))： -1.7953\n","epoch: 3, iter: 90, loss_D: 1.3162, loss_G: 2.7950;\t Scores: train D: D(x): -0.1407, D(G(z)): -0.7757 train G: D(G(z))： -2.2879\n","epoch: 3, iter: 120, loss_D: 1.3580, loss_G: 2.8748;\t Scores: train D: D(x): 3.3563, D(G(z)): 0.8761 train G: D(G(z))： -2.3943\n","epoch: 3, iter: 150, loss_D: 0.8959, loss_G: 2.1177;\t Scores: train D: D(x): 2.2653, D(G(z)): -0.0171 train G: D(G(z))： -1.5275\n","epoch: 3, iter: 180, loss_D: 1.1119, loss_G: 1.7936;\t Scores: train D: D(x): 0.1945, D(G(z)): -0.9328 train G: D(G(z))： -1.0285\n","epoch: 3, iter: 210, loss_D: 1.0303, loss_G: 1.5076;\t Scores: train D: D(x): 0.0171, D(G(z)): -1.3350 train G: D(G(z))： -0.6923\n","epoch: 3, iter: 240, loss_D: 1.1951, loss_G: 1.3477;\t Scores: train D: D(x): 2.1729, D(G(z)): 0.5248 train G: D(G(z))： -0.5601\n","epoch: 3, iter: 270, loss_D: 0.9898, loss_G: 2.3003;\t Scores: train D: D(x): 1.8119, D(G(z)): -0.1421 train G: D(G(z))： -1.7996\n","epoch: 3, iter: 300, loss_D: 0.7120, loss_G: 1.8355;\t Scores: train D: D(x): 2.5659, D(G(z)): -0.3608 train G: D(G(z))： -1.2457\n","epoch: 3, iter: 330, loss_D: 0.7935, loss_G: 2.2804;\t Scores: train D: D(x): 0.9770, D(G(z)): -0.8011 train G: D(G(z))： -1.8067\n","epoch: 3, iter: 360, loss_D: 0.7497, loss_G: 1.8888;\t Scores: train D: D(x): 0.4464, D(G(z)): -1.8632 train G: D(G(z))： -1.2700\n","epoch: 3, iter: 390, loss_D: 0.9631, loss_G: 1.3794;\t Scores: train D: D(x): 0.0400, D(G(z)): -2.0670 train G: D(G(z))： -0.2930\n","epoch: 3, iter: 420, loss_D: 0.9120, loss_G: 1.2961;\t Scores: train D: D(x): 0.6798, D(G(z)): -0.9481 train G: D(G(z))： -0.3883\n","epoch: 3, iter: 450, loss_D: 1.7830, loss_G: 2.2930;\t Scores: train D: D(x): 0.5262, D(G(z)): 0.7514 train G: D(G(z))： -1.5867\n","epoch: 3, iter: 480, loss_D: 0.8850, loss_G: 2.8123;\t Scores: train D: D(x): 1.2811, D(G(z)): -0.5796 train G: D(G(z))： -2.2055\n","epoch: 3, iter: 510, loss_D: 0.6826, loss_G: 1.5771;\t Scores: train D: D(x): 1.7006, D(G(z)): -0.7133 train G: D(G(z))： -0.8297\n","epoch: 3, iter: 540, loss_D: 0.7295, loss_G: 2.5641;\t Scores: train D: D(x): 1.4222, D(G(z)): -0.8262 train G: D(G(z))： -2.1046\n","epoch: 3, iter: 570, loss_D: 1.9569, loss_G: 1.8836;\t Scores: train D: D(x): -0.9732, D(G(z)): -0.4296 train G: D(G(z))： -1.1989\n","epoch: 3, iter: 600, loss_D: 1.9326, loss_G: 1.2205;\t Scores: train D: D(x): -1.5662, D(G(z)): -2.8140 train G: D(G(z))： -0.1536\n","epoch: 3, iter: 630, loss_D: 0.7702, loss_G: 1.5814;\t Scores: train D: D(x): 1.1031, D(G(z)): -0.8522 train G: D(G(z))： -0.6756\n","epoch: 3, iter: 660, loss_D: 0.5716, loss_G: 1.8867;\t Scores: train D: D(x): 1.0015, D(G(z)): -1.8048 train G: D(G(z))： -1.2643\n","epoch: 3, iter: 690, loss_D: 0.6511, loss_G: 2.7275;\t Scores: train D: D(x): 1.0166, D(G(z)): -1.4348 train G: D(G(z))： -2.3197\n","epoch: 3, iter: 720, loss_D: 1.3640, loss_G: 2.0397;\t Scores: train D: D(x): 0.4005, D(G(z)): -0.3311 train G: D(G(z))： -1.4436\n","epoch: 3, iter: 750, loss_D: 0.7890, loss_G: 1.5400;\t Scores: train D: D(x): 0.2070, D(G(z)): -2.6827 train G: D(G(z))： -0.8052\n","epoch: 3, iter: 780, loss_D: 0.5930, loss_G: 1.8847;\t Scores: train D: D(x): 1.2106, D(G(z)): -1.7585 train G: D(G(z))： -1.2860\n","epoch: 3, iter: 810, loss_D: 1.4864, loss_G: 4.5928;\t Scores: train D: D(x): 2.8163, D(G(z)): 0.8660 train G: D(G(z))： -4.2380\n","epoch: 3, iter: 840, loss_D: 0.8912, loss_G: 1.5895;\t Scores: train D: D(x): 1.7662, D(G(z)): -0.3503 train G: D(G(z))： -0.8984\n","epoch: 3, iter: 870, loss_D: 1.3864, loss_G: 2.4813;\t Scores: train D: D(x): -0.8294, D(G(z)): -2.2954 train G: D(G(z))： -1.9618\n","epoch: 3, iter: 900, loss_D: 0.9580, loss_G: 3.3693;\t Scores: train D: D(x): -0.1155, D(G(z)): -2.3347 train G: D(G(z))： -2.9324\n","epoch: 3, iter: 930, loss_D: 1.0524, loss_G: 4.1446;\t Scores: train D: D(x): 1.0731, D(G(z)): -0.4205 train G: D(G(z))： -3.6949\n","epoch: 3, iter: 960, loss_D: 0.6613, loss_G: 2.6792;\t Scores: train D: D(x): 1.3522, D(G(z)): -1.1854 train G: D(G(z))： -2.0455\n","epoch: 3, iter: 990, loss_D: 0.9609, loss_G: 2.9949;\t Scores: train D: D(x): 0.6209, D(G(z)): -0.8882 train G: D(G(z))： -2.4594\n","epoch: 3, iter: 1020, loss_D: 0.6536, loss_G: 2.3374;\t Scores: train D: D(x): 0.8615, D(G(z)): -2.3137 train G: D(G(z))： -1.7263\n","epoch: 3, iter: 1050, loss_D: 0.6485, loss_G: 3.2284;\t Scores: train D: D(x): 2.8926, D(G(z)): -0.4492 train G: D(G(z))： -2.7992\n","epoch: 3, iter: 1080, loss_D: 2.3659, loss_G: 0.8348;\t Scores: train D: D(x): -2.0791, D(G(z)): -2.2071 train G: D(G(z))： 0.5511\n","epoch: 3, iter: 1110, loss_D: 0.6639, loss_G: 2.0930;\t Scores: train D: D(x): 0.9269, D(G(z)): -1.4838 train G: D(G(z))： -1.4217\n","epoch: 3, iter: 1140, loss_D: 1.0423, loss_G: 3.2701;\t Scores: train D: D(x): 0.0913, D(G(z)): -2.5957 train G: D(G(z))： -2.8590\n","epoch: 3, iter: 1170, loss_D: 1.1395, loss_G: 1.9257;\t Scores: train D: D(x): 0.1599, D(G(z)): -1.1071 train G: D(G(z))： -1.2134\n","epoch: 3, iter: 1200, loss_D: 0.9279, loss_G: 3.3133;\t Scores: train D: D(x): 1.6776, D(G(z)): -0.2889 train G: D(G(z))： -2.8064\n","epoch: 3, iter: 1230, loss_D: 0.5230, loss_G: 2.8626;\t Scores: train D: D(x): 1.9396, D(G(z)): -1.4924 train G: D(G(z))： -2.3611\n","epoch: 3, iter: 1260, loss_D: 0.6249, loss_G: 2.0855;\t Scores: train D: D(x): 2.6315, D(G(z)): -0.5209 train G: D(G(z))： -1.5030\n","epoch: 3, iter: 1290, loss_D: 0.8846, loss_G: 1.7021;\t Scores: train D: D(x): 0.9165, D(G(z)): -1.1331 train G: D(G(z))： -0.9976\n","epoch: 3, iter: 1320, loss_D: 1.0003, loss_G: 2.4431;\t Scores: train D: D(x): 2.3649, D(G(z)): 0.0807 train G: D(G(z))： -1.9790\n","epoch: 4, iter: 30, loss_D: 1.0481, loss_G: 2.0662;\t Scores: train D: D(x): 0.7582, D(G(z)): -0.7859 train G: D(G(z))： -1.4527\n","epoch: 4, iter: 60, loss_D: 0.8336, loss_G: 1.4447;\t Scores: train D: D(x): 0.4196, D(G(z)): -1.6841 train G: D(G(z))： -0.5936\n","epoch: 4, iter: 90, loss_D: 0.9181, loss_G: 2.6016;\t Scores: train D: D(x): 0.4896, D(G(z)): -1.3906 train G: D(G(z))： -2.1033\n","epoch: 4, iter: 120, loss_D: 0.7537, loss_G: 2.3124;\t Scores: train D: D(x): 0.5180, D(G(z)): -2.2114 train G: D(G(z))： -1.8708\n","epoch: 4, iter: 150, loss_D: 0.6605, loss_G: 1.7666;\t Scores: train D: D(x): 1.2144, D(G(z)): -1.8219 train G: D(G(z))： -1.0416\n","epoch: 4, iter: 180, loss_D: 1.3103, loss_G: 1.6081;\t Scores: train D: D(x): 0.6980, D(G(z)): -0.0404 train G: D(G(z))： -0.7389\n","epoch: 4, iter: 210, loss_D: 1.0058, loss_G: 1.7918;\t Scores: train D: D(x): 0.5407, D(G(z)): -0.9874 train G: D(G(z))： -1.1656\n","epoch: 4, iter: 240, loss_D: 1.2442, loss_G: 2.6732;\t Scores: train D: D(x): 0.3631, D(G(z)): -0.3661 train G: D(G(z))： -2.2067\n","epoch: 4, iter: 270, loss_D: 1.7575, loss_G: 1.7399;\t Scores: train D: D(x): -1.3808, D(G(z)): -3.3940 train G: D(G(z))： -0.9429\n","epoch: 4, iter: 300, loss_D: 0.8611, loss_G: 2.9057;\t Scores: train D: D(x): 0.1850, D(G(z)): -2.7827 train G: D(G(z))： -2.4456\n","epoch: 4, iter: 330, loss_D: 1.3649, loss_G: 1.9591;\t Scores: train D: D(x): -0.6310, D(G(z)): -2.0628 train G: D(G(z))： -1.2580\n","epoch: 4, iter: 360, loss_D: 0.9958, loss_G: 2.0120;\t Scores: train D: D(x): 0.7044, D(G(z)): -0.5555 train G: D(G(z))： -1.4815\n","epoch: 4, iter: 390, loss_D: 0.7013, loss_G: 2.6131;\t Scores: train D: D(x): 0.3775, D(G(z)): -4.0220 train G: D(G(z))： -2.1116\n","epoch: 4, iter: 420, loss_D: 0.7272, loss_G: 1.7847;\t Scores: train D: D(x): 2.1235, D(G(z)): -0.7734 train G: D(G(z))： -1.0164\n","epoch: 4, iter: 450, loss_D: 0.4558, loss_G: 1.3053;\t Scores: train D: D(x): 2.3245, D(G(z)): -1.3429 train G: D(G(z))： -0.3326\n","epoch: 4, iter: 480, loss_D: 0.9605, loss_G: 2.0893;\t Scores: train D: D(x): 0.3669, D(G(z)): -1.4355 train G: D(G(z))： -1.5137\n","epoch: 4, iter: 510, loss_D: 0.5743, loss_G: 2.7109;\t Scores: train D: D(x): 1.6093, D(G(z)): -1.5242 train G: D(G(z))： -2.2146\n","epoch: 4, iter: 540, loss_D: 0.8977, loss_G: 2.9476;\t Scores: train D: D(x): 1.3675, D(G(z)): -0.9686 train G: D(G(z))： -2.4266\n","epoch: 4, iter: 570, loss_D: 1.4224, loss_G: 2.6608;\t Scores: train D: D(x): -0.4696, D(G(z)): -1.0369 train G: D(G(z))： -2.1132\n","epoch: 4, iter: 600, loss_D: 0.7107, loss_G: 4.4393;\t Scores: train D: D(x): 0.7427, D(G(z)): -2.2677 train G: D(G(z))： -4.0838\n","epoch: 4, iter: 630, loss_D: 0.9190, loss_G: 1.4926;\t Scores: train D: D(x): 0.1173, D(G(z)): -2.0035 train G: D(G(z))： -0.6028\n","epoch: 4, iter: 660, loss_D: 0.4573, loss_G: 2.6011;\t Scores: train D: D(x): 1.3146, D(G(z)): -2.6996 train G: D(G(z))： -2.0644\n","epoch: 4, iter: 690, loss_D: 0.5644, loss_G: 2.0223;\t Scores: train D: D(x): 2.0909, D(G(z)): -1.1422 train G: D(G(z))： -1.2995\n","epoch: 4, iter: 720, loss_D: 0.5371, loss_G: 2.9893;\t Scores: train D: D(x): 1.9137, D(G(z)): -1.9738 train G: D(G(z))： -2.6006\n","epoch: 4, iter: 750, loss_D: 0.6444, loss_G: 2.6267;\t Scores: train D: D(x): 1.3182, D(G(z)): -1.3003 train G: D(G(z))： -2.1696\n","epoch: 4, iter: 780, loss_D: 0.5642, loss_G: 3.2429;\t Scores: train D: D(x): 1.5028, D(G(z)): -1.7514 train G: D(G(z))： -2.8291\n","epoch: 4, iter: 810, loss_D: 0.6058, loss_G: 2.2736;\t Scores: train D: D(x): 1.4066, D(G(z)): -1.8696 train G: D(G(z))： -1.7211\n","epoch: 4, iter: 840, loss_D: 0.5866, loss_G: 1.9426;\t Scores: train D: D(x): 1.6534, D(G(z)): -1.4589 train G: D(G(z))： -1.2557\n","epoch: 4, iter: 870, loss_D: 0.5922, loss_G: 2.5766;\t Scores: train D: D(x): 1.4483, D(G(z)): -1.2960 train G: D(G(z))： -2.1188\n","epoch: 4, iter: 900, loss_D: 0.4066, loss_G: 2.3575;\t Scores: train D: D(x): 2.8200, D(G(z)): -1.1444 train G: D(G(z))： -1.7888\n","epoch: 4, iter: 930, loss_D: 0.8518, loss_G: 3.6667;\t Scores: train D: D(x): 1.4914, D(G(z)): -0.8698 train G: D(G(z))： -3.1833\n","epoch: 4, iter: 960, loss_D: 0.4913, loss_G: 1.5006;\t Scores: train D: D(x): 3.3197, D(G(z)): -1.1478 train G: D(G(z))： -0.4324\n","epoch: 4, iter: 990, loss_D: 0.8719, loss_G: 3.1962;\t Scores: train D: D(x): 2.2006, D(G(z)): -0.2164 train G: D(G(z))： -2.5619\n","epoch: 4, iter: 1020, loss_D: 1.0016, loss_G: 3.6503;\t Scores: train D: D(x): 2.4664, D(G(z)): -0.1259 train G: D(G(z))： -3.2776\n","epoch: 4, iter: 1050, loss_D: 0.5691, loss_G: 2.7607;\t Scores: train D: D(x): 1.8300, D(G(z)): -2.1795 train G: D(G(z))： -2.2129\n","epoch: 4, iter: 1080, loss_D: 0.6736, loss_G: 2.5452;\t Scores: train D: D(x): 0.4435, D(G(z)): -3.1519 train G: D(G(z))： -2.0401\n","epoch: 4, iter: 1110, loss_D: 0.5377, loss_G: 4.1899;\t Scores: train D: D(x): 1.6875, D(G(z)): -1.9678 train G: D(G(z))： -3.6161\n","epoch: 4, iter: 1140, loss_D: 0.5706, loss_G: 3.6725;\t Scores: train D: D(x): 2.5049, D(G(z)): -1.5023 train G: D(G(z))： -3.1244\n","epoch: 4, iter: 1170, loss_D: 0.2573, loss_G: 3.3507;\t Scores: train D: D(x): 2.6167, D(G(z)): -2.9320 train G: D(G(z))： -2.9919\n","epoch: 4, iter: 1200, loss_D: 0.4960, loss_G: 2.6830;\t Scores: train D: D(x): 2.3824, D(G(z)): -1.3031 train G: D(G(z))： -2.1298\n","epoch: 4, iter: 1230, loss_D: 0.3527, loss_G: 4.1207;\t Scores: train D: D(x): 2.4815, D(G(z)): -2.3335 train G: D(G(z))： -3.6925\n","epoch: 4, iter: 1260, loss_D: 0.4682, loss_G: 1.9985;\t Scores: train D: D(x): 1.3223, D(G(z)): -3.1483 train G: D(G(z))： -1.2929\n","epoch: 4, iter: 1290, loss_D: 1.2078, loss_G: 2.1297;\t Scores: train D: D(x): 3.7863, D(G(z)): 0.4836 train G: D(G(z))： -1.4367\n","epoch: 4, iter: 1320, loss_D: 0.4750, loss_G: 2.8082;\t Scores: train D: D(x): 2.1034, D(G(z)): -2.0465 train G: D(G(z))： -2.3127\n","epoch: 5, iter: 30, loss_D: 0.7081, loss_G: 3.0225;\t Scores: train D: D(x): 2.8136, D(G(z)): -0.7970 train G: D(G(z))： -2.4214\n","epoch: 5, iter: 60, loss_D: 0.7823, loss_G: 1.8717;\t Scores: train D: D(x): 2.6988, D(G(z)): -0.5092 train G: D(G(z))： -1.1237\n","epoch: 5, iter: 90, loss_D: 0.3781, loss_G: 3.9157;\t Scores: train D: D(x): 2.1215, D(G(z)): -2.2646 train G: D(G(z))： -3.4152\n","epoch: 5, iter: 120, loss_D: 0.4531, loss_G: 4.4952;\t Scores: train D: D(x): 1.9837, D(G(z)): -3.0899 train G: D(G(z))： -4.1321\n","epoch: 5, iter: 150, loss_D: 0.7582, loss_G: 2.0187;\t Scores: train D: D(x): 2.2953, D(G(z)): -1.1188 train G: D(G(z))： -1.3303\n","epoch: 5, iter: 180, loss_D: 0.6020, loss_G: 2.3634;\t Scores: train D: D(x): 2.1077, D(G(z)): -1.4822 train G: D(G(z))： -1.7433\n","epoch: 5, iter: 210, loss_D: 0.7497, loss_G: 3.4045;\t Scores: train D: D(x): 1.3866, D(G(z)): -1.3710 train G: D(G(z))： -3.0184\n","epoch: 5, iter: 240, loss_D: 0.7336, loss_G: 2.9859;\t Scores: train D: D(x): 2.2413, D(G(z)): -1.0000 train G: D(G(z))： -2.4358\n","epoch: 5, iter: 270, loss_D: 1.1681, loss_G: 3.4073;\t Scores: train D: D(x): 2.9220, D(G(z)): 0.3611 train G: D(G(z))： -2.9638\n","epoch: 5, iter: 300, loss_D: 0.9894, loss_G: 1.0168;\t Scores: train D: D(x): 0.5690, D(G(z)): -1.1019 train G: D(G(z))： 0.1077\n","epoch: 5, iter: 330, loss_D: 0.8542, loss_G: 3.2422;\t Scores: train D: D(x): 2.6876, D(G(z)): -0.2567 train G: D(G(z))： -2.8220\n","epoch: 5, iter: 360, loss_D: 1.4691, loss_G: 1.8482;\t Scores: train D: D(x): -0.0179, D(G(z)): -1.0622 train G: D(G(z))： -1.0928\n","epoch: 5, iter: 390, loss_D: 0.7182, loss_G: 2.2551;\t Scores: train D: D(x): 1.1856, D(G(z)): -1.2118 train G: D(G(z))： -1.6659\n","epoch: 5, iter: 420, loss_D: 0.8331, loss_G: 2.0708;\t Scores: train D: D(x): 0.4643, D(G(z)): -2.3390 train G: D(G(z))： -1.3568\n","epoch: 5, iter: 450, loss_D: 0.2502, loss_G: 3.9359;\t Scores: train D: D(x): 2.6410, D(G(z)): -2.7224 train G: D(G(z))： -3.6078\n","epoch: 5, iter: 480, loss_D: 0.5968, loss_G: 2.2924;\t Scores: train D: D(x): 1.3106, D(G(z)): -1.9858 train G: D(G(z))： -1.6848\n","epoch: 5, iter: 510, loss_D: 1.0821, loss_G: 7.0595;\t Scores: train D: D(x): 2.2901, D(G(z)): -0.0726 train G: D(G(z))： -6.5359\n","epoch: 5, iter: 540, loss_D: 0.7380, loss_G: 2.5279;\t Scores: train D: D(x): 1.4055, D(G(z)): -1.4092 train G: D(G(z))： -2.0579\n","epoch: 5, iter: 570, loss_D: 0.4555, loss_G: 2.9653;\t Scores: train D: D(x): 2.4242, D(G(z)): -1.5176 train G: D(G(z))： -2.5079\n","epoch: 5, iter: 600, loss_D: 0.8085, loss_G: 2.5557;\t Scores: train D: D(x): 0.7341, D(G(z)): -3.4707 train G: D(G(z))： -1.9176\n","epoch: 5, iter: 630, loss_D: 1.4147, loss_G: 3.0576;\t Scores: train D: D(x): 3.2738, D(G(z)): 0.8261 train G: D(G(z))： -2.5259\n","epoch: 5, iter: 660, loss_D: 0.6865, loss_G: 3.2760;\t Scores: train D: D(x): 1.9360, D(G(z)): -1.2852 train G: D(G(z))： -2.7422\n","epoch: 5, iter: 690, loss_D: 0.7509, loss_G: 1.5761;\t Scores: train D: D(x): 0.5134, D(G(z)): -2.3669 train G: D(G(z))： -0.7865\n","epoch: 5, iter: 720, loss_D: 0.2390, loss_G: 4.0224;\t Scores: train D: D(x): 2.7754, D(G(z)): -3.9511 train G: D(G(z))： -3.6108\n","epoch: 5, iter: 750, loss_D: 0.4236, loss_G: 4.6393;\t Scores: train D: D(x): 3.5675, D(G(z)): -1.8426 train G: D(G(z))： -4.1921\n","epoch: 5, iter: 780, loss_D: 1.0743, loss_G: 5.0136;\t Scores: train D: D(x): 3.0636, D(G(z)): 0.0101 train G: D(G(z))： -4.5830\n","epoch: 5, iter: 810, loss_D: 0.5204, loss_G: 2.8608;\t Scores: train D: D(x): 2.9015, D(G(z)): -1.4340 train G: D(G(z))： -2.3284\n","epoch: 5, iter: 840, loss_D: 0.9350, loss_G: 1.9743;\t Scores: train D: D(x): 0.2228, D(G(z)): -2.1612 train G: D(G(z))： -1.3058\n","epoch: 5, iter: 870, loss_D: 0.4883, loss_G: 3.4610;\t Scores: train D: D(x): 3.3906, D(G(z)): -1.5284 train G: D(G(z))： -2.8909\n","epoch: 5, iter: 900, loss_D: 1.3712, loss_G: 2.3704;\t Scores: train D: D(x): -0.5828, D(G(z)): -2.1625 train G: D(G(z))： -1.5344\n","epoch: 5, iter: 930, loss_D: 0.3912, loss_G: 1.9309;\t Scores: train D: D(x): 2.4996, D(G(z)): -2.2954 train G: D(G(z))： -1.1104\n","epoch: 5, iter: 960, loss_D: 0.6870, loss_G: 1.9664;\t Scores: train D: D(x): 0.8823, D(G(z)): -3.8575 train G: D(G(z))： -1.1823\n","epoch: 5, iter: 990, loss_D: 1.2256, loss_G: 7.7256;\t Scores: train D: D(x): 2.3262, D(G(z)): -0.2078 train G: D(G(z))： -7.2119\n","epoch: 5, iter: 1020, loss_D: 0.4294, loss_G: 2.8215;\t Scores: train D: D(x): 3.6644, D(G(z)): -1.7648 train G: D(G(z))： -2.3175\n","epoch: 5, iter: 1050, loss_D: 0.5855, loss_G: 2.0653;\t Scores: train D: D(x): 1.6121, D(G(z)): -2.0305 train G: D(G(z))： -1.3506\n","epoch: 5, iter: 1080, loss_D: 0.8022, loss_G: 2.8419;\t Scores: train D: D(x): 2.1526, D(G(z)): -0.7029 train G: D(G(z))： -2.3836\n","epoch: 5, iter: 1110, loss_D: 0.8492, loss_G: 0.9355;\t Scores: train D: D(x): 0.8298, D(G(z)): -1.3982 train G: D(G(z))： 0.6226\n","epoch: 5, iter: 1140, loss_D: 0.6534, loss_G: 2.7992;\t Scores: train D: D(x): 1.8131, D(G(z)): -1.0442 train G: D(G(z))： -2.3700\n","epoch: 5, iter: 1170, loss_D: 0.1381, loss_G: 4.2128;\t Scores: train D: D(x): 3.2604, D(G(z)): -3.5451 train G: D(G(z))： -3.7764\n","epoch: 5, iter: 1200, loss_D: 0.4871, loss_G: 4.4631;\t Scores: train D: D(x): 1.7044, D(G(z)): -2.6752 train G: D(G(z))： -4.0836\n","epoch: 5, iter: 1230, loss_D: 0.6537, loss_G: 2.8819;\t Scores: train D: D(x): 0.5597, D(G(z)): -3.7739 train G: D(G(z))： -2.3437\n","epoch: 5, iter: 1260, loss_D: 0.4704, loss_G: 3.0267;\t Scores: train D: D(x): 1.8364, D(G(z)): -2.7523 train G: D(G(z))： -2.5982\n","epoch: 5, iter: 1290, loss_D: 0.7509, loss_G: 1.0736;\t Scores: train D: D(x): 2.1887, D(G(z)): -0.8774 train G: D(G(z))： 0.4956\n","epoch: 5, iter: 1320, loss_D: 0.4893, loss_G: 3.6084;\t Scores: train D: D(x): 2.2161, D(G(z)): -1.6705 train G: D(G(z))： -2.9603\n","epoch: 6, iter: 30, loss_D: 0.6155, loss_G: 2.9860;\t Scores: train D: D(x): 1.3553, D(G(z)): -2.6162 train G: D(G(z))： -2.4947\n","epoch: 6, iter: 60, loss_D: 0.4868, loss_G: 3.0548;\t Scores: train D: D(x): 2.3958, D(G(z)): -1.9159 train G: D(G(z))： -2.6250\n","epoch: 6, iter: 90, loss_D: 1.6616, loss_G: 3.7811;\t Scores: train D: D(x): 1.6115, D(G(z)): 0.7534 train G: D(G(z))： -3.3383\n","epoch: 6, iter: 120, loss_D: 0.2990, loss_G: 2.0430;\t Scores: train D: D(x): 2.2997, D(G(z)): -3.2345 train G: D(G(z))： -1.4022\n","epoch: 6, iter: 150, loss_D: 1.0198, loss_G: 1.8543;\t Scores: train D: D(x): 0.0372, D(G(z)): -3.0694 train G: D(G(z))： -0.9766\n","epoch: 6, iter: 180, loss_D: 0.6998, loss_G: 2.3845;\t Scores: train D: D(x): 0.6961, D(G(z)): -2.8477 train G: D(G(z))： -1.8509\n","epoch: 6, iter: 210, loss_D: 0.3875, loss_G: 3.5145;\t Scores: train D: D(x): 3.7208, D(G(z)): -2.0099 train G: D(G(z))： -2.9688\n","epoch: 6, iter: 240, loss_D: 0.1405, loss_G: 2.3541;\t Scores: train D: D(x): 4.4652, D(G(z)): -3.0356 train G: D(G(z))： -1.7832\n","epoch: 6, iter: 270, loss_D: 0.3832, loss_G: 2.1796;\t Scores: train D: D(x): 2.1715, D(G(z)): -3.8417 train G: D(G(z))： -1.3425\n","epoch: 6, iter: 300, loss_D: 0.1846, loss_G: 3.6535;\t Scores: train D: D(x): 3.3623, D(G(z)): -3.6044 train G: D(G(z))： -3.0653\n","epoch: 6, iter: 330, loss_D: 0.3898, loss_G: 5.0872;\t Scores: train D: D(x): 2.6173, D(G(z)): -2.3803 train G: D(G(z))： -4.6420\n","epoch: 6, iter: 360, loss_D: 0.9375, loss_G: 3.7018;\t Scores: train D: D(x): 3.5837, D(G(z)): -0.1646 train G: D(G(z))： -3.2343\n","epoch: 6, iter: 390, loss_D: 0.7629, loss_G: 3.7485;\t Scores: train D: D(x): 1.0606, D(G(z)): -2.7553 train G: D(G(z))： -3.3318\n","epoch: 6, iter: 420, loss_D: 0.2811, loss_G: 4.0219;\t Scores: train D: D(x): 3.9734, D(G(z)): -2.5805 train G: D(G(z))： -3.6177\n","epoch: 6, iter: 450, loss_D: 0.8530, loss_G: 5.1453;\t Scores: train D: D(x): 4.4598, D(G(z)): -0.8414 train G: D(G(z))： -4.6831\n","epoch: 6, iter: 480, loss_D: 0.5828, loss_G: 2.2346;\t Scores: train D: D(x): 3.1826, D(G(z)): -0.9877 train G: D(G(z))： -1.5265\n","epoch: 6, iter: 510, loss_D: 0.7279, loss_G: 3.7664;\t Scores: train D: D(x): 4.0825, D(G(z)): -0.6083 train G: D(G(z))： -3.3999\n","epoch: 6, iter: 540, loss_D: 0.4156, loss_G: 2.4743;\t Scores: train D: D(x): 2.2476, D(G(z)): -3.4732 train G: D(G(z))： -1.6773\n","epoch: 6, iter: 570, loss_D: 0.9853, loss_G: 1.1906;\t Scores: train D: D(x): 0.2903, D(G(z)): -3.1810 train G: D(G(z))： 0.0841\n","epoch: 6, iter: 600, loss_D: 0.6202, loss_G: 3.8298;\t Scores: train D: D(x): 2.7150, D(G(z)): -1.0856 train G: D(G(z))： -3.3821\n","epoch: 6, iter: 630, loss_D: 1.2474, loss_G: 2.2415;\t Scores: train D: D(x): -0.5020, D(G(z)): -2.7559 train G: D(G(z))： -1.2511\n","epoch: 6, iter: 660, loss_D: 0.8076, loss_G: 4.4147;\t Scores: train D: D(x): 4.9580, D(G(z)): -0.1705 train G: D(G(z))： -3.8884\n","epoch: 6, iter: 690, loss_D: 0.3469, loss_G: 4.2265;\t Scores: train D: D(x): 2.8123, D(G(z)): -2.4081 train G: D(G(z))： -3.6630\n","epoch: 6, iter: 720, loss_D: 0.3284, loss_G: 3.3051;\t Scores: train D: D(x): 2.7708, D(G(z)): -3.5496 train G: D(G(z))： -2.7177\n","epoch: 6, iter: 750, loss_D: 0.5581, loss_G: 2.1840;\t Scores: train D: D(x): 1.0764, D(G(z)): -2.8370 train G: D(G(z))： -1.4704\n","epoch: 6, iter: 780, loss_D: 0.4853, loss_G: 3.1765;\t Scores: train D: D(x): 4.9695, D(G(z)): -1.8672 train G: D(G(z))： -2.6326\n","epoch: 6, iter: 810, loss_D: 0.4841, loss_G: 3.0339;\t Scores: train D: D(x): 2.0210, D(G(z)): -2.2057 train G: D(G(z))： -2.5126\n","epoch: 6, iter: 840, loss_D: 0.4983, loss_G: 3.6487;\t Scores: train D: D(x): 1.3256, D(G(z)): -3.5834 train G: D(G(z))： -3.2295\n","epoch: 6, iter: 870, loss_D: 0.2863, loss_G: 3.4891;\t Scores: train D: D(x): 3.0297, D(G(z)): -3.4052 train G: D(G(z))： -3.0372\n","epoch: 6, iter: 900, loss_D: 0.4270, loss_G: 4.9502;\t Scores: train D: D(x): 2.5350, D(G(z)): -2.8152 train G: D(G(z))： -4.4307\n","epoch: 6, iter: 930, loss_D: 0.4423, loss_G: 2.7989;\t Scores: train D: D(x): 2.0725, D(G(z)): -2.6021 train G: D(G(z))： -1.9951\n","epoch: 6, iter: 960, loss_D: 0.7212, loss_G: 2.9516;\t Scores: train D: D(x): 1.2089, D(G(z)): -2.6380 train G: D(G(z))： -2.3558\n","epoch: 6, iter: 990, loss_D: 0.7801, loss_G: 2.9920;\t Scores: train D: D(x): 2.0271, D(G(z)): -1.1081 train G: D(G(z))： -2.4579\n","epoch: 6, iter: 1020, loss_D: 0.4376, loss_G: 2.0969;\t Scores: train D: D(x): 3.9910, D(G(z)): -1.2201 train G: D(G(z))： -1.4785\n","epoch: 6, iter: 1050, loss_D: 1.0479, loss_G: 2.9124;\t Scores: train D: D(x): 1.1401, D(G(z)): -1.6737 train G: D(G(z))： -2.3370\n","epoch: 6, iter: 1080, loss_D: 0.7008, loss_G: 4.5843;\t Scores: train D: D(x): 0.5945, D(G(z)): -3.7262 train G: D(G(z))： -4.2138\n","epoch: 6, iter: 1110, loss_D: 0.5223, loss_G: 3.3452;\t Scores: train D: D(x): 2.6702, D(G(z)): -3.2258 train G: D(G(z))： -2.8672\n","epoch: 6, iter: 1140, loss_D: 0.3696, loss_G: 5.0805;\t Scores: train D: D(x): 1.8792, D(G(z)): -3.2918 train G: D(G(z))： -4.6942\n","epoch: 6, iter: 1170, loss_D: 0.6821, loss_G: 2.9130;\t Scores: train D: D(x): 1.3947, D(G(z)): -2.3590 train G: D(G(z))： -2.1969\n","epoch: 6, iter: 1200, loss_D: 0.6277, loss_G: 1.9248;\t Scores: train D: D(x): 0.8757, D(G(z)): -3.4026 train G: D(G(z))： -0.7701\n","epoch: 6, iter: 1230, loss_D: 0.6634, loss_G: 7.2070;\t Scores: train D: D(x): 4.2121, D(G(z)): -0.6604 train G: D(G(z))： -6.8400\n","epoch: 6, iter: 1260, loss_D: 0.3251, loss_G: 3.2441;\t Scores: train D: D(x): 2.3350, D(G(z)): -3.0802 train G: D(G(z))： -2.7538\n","epoch: 6, iter: 1290, loss_D: 0.3253, loss_G: 3.4735;\t Scores: train D: D(x): 3.0523, D(G(z)): -3.5416 train G: D(G(z))： -2.9646\n","epoch: 6, iter: 1320, loss_D: 0.9439, loss_G: 5.2258;\t Scores: train D: D(x): 3.4237, D(G(z)): -0.4129 train G: D(G(z))： -4.7457\n","epoch: 7, iter: 30, loss_D: 0.2785, loss_G: 3.5590;\t Scores: train D: D(x): 3.5407, D(G(z)): -3.3035 train G: D(G(z))： -3.0052\n","epoch: 7, iter: 60, loss_D: 0.3593, loss_G: 3.3284;\t Scores: train D: D(x): 1.7812, D(G(z)): -3.8908 train G: D(G(z))： -2.7905\n","epoch: 7, iter: 90, loss_D: 0.5137, loss_G: 4.2817;\t Scores: train D: D(x): 2.2574, D(G(z)): -2.0430 train G: D(G(z))： -3.7845\n","epoch: 7, iter: 120, loss_D: 0.5010, loss_G: 3.2010;\t Scores: train D: D(x): 1.4994, D(G(z)): -2.1922 train G: D(G(z))： -2.7874\n","epoch: 7, iter: 150, loss_D: 0.3043, loss_G: 3.0293;\t Scores: train D: D(x): 2.4615, D(G(z)): -3.9628 train G: D(G(z))： -2.4190\n","epoch: 7, iter: 180, loss_D: 0.3847, loss_G: 3.4690;\t Scores: train D: D(x): 2.4219, D(G(z)): -2.3579 train G: D(G(z))： -3.0000\n","epoch: 7, iter: 210, loss_D: 0.4366, loss_G: 5.1819;\t Scores: train D: D(x): 1.6015, D(G(z)): -4.7216 train G: D(G(z))： -4.7754\n","epoch: 7, iter: 240, loss_D: 0.7984, loss_G: 3.1126;\t Scores: train D: D(x): 2.0195, D(G(z)): -0.9993 train G: D(G(z))： -2.6266\n","epoch: 7, iter: 270, loss_D: 0.5425, loss_G: 2.9625;\t Scores: train D: D(x): 2.4481, D(G(z)): -2.1879 train G: D(G(z))： -2.2838\n","epoch: 7, iter: 300, loss_D: 0.7854, loss_G: 4.0197;\t Scores: train D: D(x): 1.1102, D(G(z)): -2.8656 train G: D(G(z))： -3.5532\n","epoch: 7, iter: 330, loss_D: 0.1733, loss_G: 5.0811;\t Scores: train D: D(x): 3.9173, D(G(z)): -3.3536 train G: D(G(z))： -4.6140\n","epoch: 7, iter: 360, loss_D: 0.3384, loss_G: 4.4957;\t Scores: train D: D(x): 4.0838, D(G(z)): -2.8696 train G: D(G(z))： -4.1111\n","epoch: 7, iter: 390, loss_D: 0.4693, loss_G: 2.2308;\t Scores: train D: D(x): 2.1850, D(G(z)): -3.4284 train G: D(G(z))： -1.5734\n","epoch: 7, iter: 420, loss_D: 0.2457, loss_G: 3.1998;\t Scores: train D: D(x): 3.9957, D(G(z)): -2.5216 train G: D(G(z))： -2.7408\n","epoch: 7, iter: 450, loss_D: 0.3893, loss_G: 3.9054;\t Scores: train D: D(x): 3.5673, D(G(z)): -2.1564 train G: D(G(z))： -3.4604\n","epoch: 7, iter: 480, loss_D: 0.5860, loss_G: 4.3215;\t Scores: train D: D(x): 2.2843, D(G(z)): -1.6343 train G: D(G(z))： -3.9040\n","epoch: 7, iter: 510, loss_D: 0.5604, loss_G: 6.4121;\t Scores: train D: D(x): 1.5818, D(G(z)): -2.8125 train G: D(G(z))： -5.9942\n","epoch: 7, iter: 540, loss_D: 0.3573, loss_G: 3.8751;\t Scores: train D: D(x): 3.7710, D(G(z)): -2.8280 train G: D(G(z))： -3.4527\n","epoch: 7, iter: 570, loss_D: 0.5559, loss_G: 6.0460;\t Scores: train D: D(x): 1.4879, D(G(z)): -5.2339 train G: D(G(z))： -5.6886\n","epoch: 7, iter: 600, loss_D: 0.5657, loss_G: 3.8140;\t Scores: train D: D(x): 4.7009, D(G(z)): -1.2374 train G: D(G(z))： -3.1324\n","epoch: 7, iter: 630, loss_D: 0.4702, loss_G: 3.1842;\t Scores: train D: D(x): 2.7111, D(G(z)): -2.3732 train G: D(G(z))： -2.6767\n","epoch: 7, iter: 660, loss_D: 0.6800, loss_G: 4.5805;\t Scores: train D: D(x): 5.0616, D(G(z)): -0.5791 train G: D(G(z))： -4.1682\n","epoch: 7, iter: 690, loss_D: 0.4005, loss_G: 3.6499;\t Scores: train D: D(x): 2.7895, D(G(z)): -2.5252 train G: D(G(z))： -3.0782\n","epoch: 7, iter: 720, loss_D: 0.4094, loss_G: 3.0216;\t Scores: train D: D(x): 2.0742, D(G(z)): -2.9310 train G: D(G(z))： -2.5374\n","epoch: 7, iter: 750, loss_D: 0.5720, loss_G: 3.5733;\t Scores: train D: D(x): 1.7877, D(G(z)): -2.7243 train G: D(G(z))： -3.1042\n","epoch: 7, iter: 780, loss_D: 0.6758, loss_G: 3.7973;\t Scores: train D: D(x): 4.4342, D(G(z)): -0.5990 train G: D(G(z))： -3.3767\n","epoch: 7, iter: 810, loss_D: 0.3152, loss_G: 3.1938;\t Scores: train D: D(x): 2.6805, D(G(z)): -3.3736 train G: D(G(z))： -2.6710\n","epoch: 7, iter: 840, loss_D: 0.5079, loss_G: 2.6969;\t Scores: train D: D(x): 2.5033, D(G(z)): -2.8143 train G: D(G(z))： -2.0488\n","epoch: 7, iter: 870, loss_D: 1.0838, loss_G: 2.9468;\t Scores: train D: D(x): 0.2077, D(G(z)): -2.4455 train G: D(G(z))： -2.4774\n","epoch: 7, iter: 900, loss_D: 0.3157, loss_G: 4.1972;\t Scores: train D: D(x): 2.8979, D(G(z)): -2.7892 train G: D(G(z))： -3.7269\n","epoch: 7, iter: 930, loss_D: 0.7599, loss_G: 3.8656;\t Scores: train D: D(x): 1.6143, D(G(z)): -2.3993 train G: D(G(z))： -3.4145\n","epoch: 7, iter: 960, loss_D: 0.3875, loss_G: 4.0313;\t Scores: train D: D(x): 3.5509, D(G(z)): -2.2344 train G: D(G(z))： -3.6225\n","epoch: 7, iter: 990, loss_D: 0.4383, loss_G: 3.3241;\t Scores: train D: D(x): 2.5870, D(G(z)): -3.2261 train G: D(G(z))： -2.8465\n","epoch: 7, iter: 1020, loss_D: 0.5588, loss_G: 3.5580;\t Scores: train D: D(x): 1.3713, D(G(z)): -3.4406 train G: D(G(z))： -3.1349\n","epoch: 7, iter: 1050, loss_D: 0.4290, loss_G: 3.4220;\t Scores: train D: D(x): 2.4733, D(G(z)): -2.2773 train G: D(G(z))： -2.8049\n","epoch: 7, iter: 1080, loss_D: 0.3521, loss_G: 4.6615;\t Scores: train D: D(x): 3.2137, D(G(z)): -2.3858 train G: D(G(z))： -4.2362\n","epoch: 7, iter: 1110, loss_D: 0.4836, loss_G: 4.7409;\t Scores: train D: D(x): 1.3003, D(G(z)): -4.5686 train G: D(G(z))： -4.2875\n","epoch: 7, iter: 1140, loss_D: 0.1915, loss_G: 3.6631;\t Scores: train D: D(x): 5.6443, D(G(z)): -3.4478 train G: D(G(z))： -3.1383\n","epoch: 7, iter: 1170, loss_D: 0.4760, loss_G: 4.3297;\t Scores: train D: D(x): 3.5544, D(G(z)): -2.0472 train G: D(G(z))： -3.8190\n","epoch: 7, iter: 1200, loss_D: 1.3696, loss_G: 3.2470;\t Scores: train D: D(x): 1.0879, D(G(z)): -0.7518 train G: D(G(z))： -2.7531\n","epoch: 7, iter: 1230, loss_D: 0.5960, loss_G: 4.5657;\t Scores: train D: D(x): 2.6547, D(G(z)): -1.8166 train G: D(G(z))： -4.0004\n","epoch: 7, iter: 1260, loss_D: 0.3437, loss_G: 3.1211;\t Scores: train D: D(x): 2.2196, D(G(z)): -2.7211 train G: D(G(z))： -2.5301\n","epoch: 7, iter: 1290, loss_D: 0.4017, loss_G: 2.6406;\t Scores: train D: D(x): 2.4801, D(G(z)): -2.6417 train G: D(G(z))： -2.0899\n","epoch: 7, iter: 1320, loss_D: 0.3870, loss_G: 2.0513;\t Scores: train D: D(x): 2.9982, D(G(z)): -1.8235 train G: D(G(z))： -1.3661\n","epoch: 8, iter: 30, loss_D: 0.5919, loss_G: 2.8955;\t Scores: train D: D(x): 2.0044, D(G(z)): -1.9310 train G: D(G(z))： -2.3809\n","epoch: 8, iter: 60, loss_D: 0.3863, loss_G: 5.3650;\t Scores: train D: D(x): 3.0592, D(G(z)): -3.3308 train G: D(G(z))： -4.9359\n","epoch: 8, iter: 90, loss_D: 0.2062, loss_G: 3.0418;\t Scores: train D: D(x): 3.8998, D(G(z)): -3.4589 train G: D(G(z))： -2.5919\n","epoch: 8, iter: 120, loss_D: 0.3398, loss_G: 3.1565;\t Scores: train D: D(x): 4.8785, D(G(z)): -1.9993 train G: D(G(z))： -2.6221\n","epoch: 8, iter: 150, loss_D: 0.9189, loss_G: 4.1574;\t Scores: train D: D(x): 2.0149, D(G(z)): -0.5241 train G: D(G(z))： -3.6103\n","epoch: 8, iter: 180, loss_D: 0.1810, loss_G: 4.6947;\t Scores: train D: D(x): 2.7654, D(G(z)): -4.1036 train G: D(G(z))： -4.3386\n","epoch: 8, iter: 210, loss_D: 0.5115, loss_G: 3.0044;\t Scores: train D: D(x): 2.2653, D(G(z)): -4.4301 train G: D(G(z))： -2.3536\n","epoch: 8, iter: 240, loss_D: 0.3258, loss_G: 5.5976;\t Scores: train D: D(x): 2.1703, D(G(z)): -3.7859 train G: D(G(z))： -5.1992\n","epoch: 8, iter: 270, loss_D: 0.2617, loss_G: 3.9022;\t Scores: train D: D(x): 4.0338, D(G(z)): -2.4613 train G: D(G(z))： -3.3928\n","epoch: 8, iter: 300, loss_D: 0.2642, loss_G: 5.0479;\t Scores: train D: D(x): 2.4887, D(G(z)): -5.8831 train G: D(G(z))： -4.6455\n","epoch: 8, iter: 330, loss_D: 0.4768, loss_G: 4.3023;\t Scores: train D: D(x): 2.7502, D(G(z)): -1.7985 train G: D(G(z))： -3.9149\n","epoch: 8, iter: 360, loss_D: 0.5361, loss_G: 5.1144;\t Scores: train D: D(x): 2.4570, D(G(z)): -2.1748 train G: D(G(z))： -4.7130\n","epoch: 8, iter: 390, loss_D: 0.5539, loss_G: 3.5484;\t Scores: train D: D(x): 1.1494, D(G(z)): -3.0295 train G: D(G(z))： -3.0667\n","epoch: 8, iter: 420, loss_D: 0.6634, loss_G: 4.0325;\t Scores: train D: D(x): 3.9040, D(G(z)): -0.8761 train G: D(G(z))： -3.5555\n","epoch: 8, iter: 450, loss_D: 0.3794, loss_G: 7.1698;\t Scores: train D: D(x): 4.2307, D(G(z)): -1.5677 train G: D(G(z))： -6.7674\n","epoch: 8, iter: 480, loss_D: 0.3842, loss_G: 2.7111;\t Scores: train D: D(x): 5.0053, D(G(z)): -2.0709 train G: D(G(z))： -2.1840\n","epoch: 8, iter: 510, loss_D: 0.6743, loss_G: 5.6153;\t Scores: train D: D(x): 3.0579, D(G(z)): -0.9745 train G: D(G(z))： -5.2206\n","epoch: 8, iter: 540, loss_D: 0.1226, loss_G: 4.3867;\t Scores: train D: D(x): 4.0216, D(G(z)): -3.3998 train G: D(G(z))： -3.9194\n","epoch: 8, iter: 570, loss_D: 1.1645, loss_G: 3.3507;\t Scores: train D: D(x): -0.4061, D(G(z)): -5.3578 train G: D(G(z))： -2.8174\n","epoch: 8, iter: 600, loss_D: 1.5464, loss_G: 2.3278;\t Scores: train D: D(x): -0.8536, D(G(z)): -3.6782 train G: D(G(z))： -1.6592\n","epoch: 8, iter: 630, loss_D: 0.1900, loss_G: 3.9029;\t Scores: train D: D(x): 4.4760, D(G(z)): -3.4338 train G: D(G(z))： -3.4774\n","epoch: 8, iter: 660, loss_D: 0.3526, loss_G: 3.7103;\t Scores: train D: D(x): 3.7573, D(G(z)): -2.7628 train G: D(G(z))： -2.9878\n","epoch: 8, iter: 690, loss_D: 0.2059, loss_G: 3.4643;\t Scores: train D: D(x): 3.7042, D(G(z)): -4.2115 train G: D(G(z))： -2.9545\n","epoch: 8, iter: 720, loss_D: 0.9885, loss_G: 2.1243;\t Scores: train D: D(x): 0.7882, D(G(z)): -2.5676 train G: D(G(z))： -1.1578\n","epoch: 8, iter: 750, loss_D: 0.2008, loss_G: 3.1375;\t Scores: train D: D(x): 4.1684, D(G(z)): -3.6651 train G: D(G(z))： -2.4101\n","epoch: 8, iter: 780, loss_D: 0.1602, loss_G: 7.9748;\t Scores: train D: D(x): 4.4190, D(G(z)): -4.6488 train G: D(G(z))： -7.6239\n","epoch: 8, iter: 810, loss_D: 0.4790, loss_G: 4.4690;\t Scores: train D: D(x): 1.8114, D(G(z)): -4.9944 train G: D(G(z))： -3.9375\n","epoch: 8, iter: 840, loss_D: 0.3563, loss_G: 3.4368;\t Scores: train D: D(x): 2.3273, D(G(z)): -3.2240 train G: D(G(z))： -2.8905\n","epoch: 8, iter: 870, loss_D: 0.3409, loss_G: 4.2235;\t Scores: train D: D(x): 2.4821, D(G(z)): -3.9043 train G: D(G(z))： -3.6855\n","epoch: 8, iter: 900, loss_D: 0.5561, loss_G: 3.4197;\t Scores: train D: D(x): 7.0159, D(G(z)): -1.1368 train G: D(G(z))： -2.9133\n","epoch: 8, iter: 930, loss_D: 0.1827, loss_G: 4.0134;\t Scores: train D: D(x): 4.6445, D(G(z)): -4.0269 train G: D(G(z))： -3.6585\n","epoch: 8, iter: 960, loss_D: 0.5081, loss_G: 5.4721;\t Scores: train D: D(x): 4.1075, D(G(z)): -1.6943 train G: D(G(z))： -4.9240\n","epoch: 8, iter: 990, loss_D: 0.1839, loss_G: 5.4641;\t Scores: train D: D(x): 5.4038, D(G(z)): -3.1090 train G: D(G(z))： -4.8896\n","epoch: 8, iter: 1020, loss_D: 1.0396, loss_G: 1.9770;\t Scores: train D: D(x): 0.6384, D(G(z)): -1.7720 train G: D(G(z))： -0.8492\n"],"name":"stdout"}]},{"metadata":{"id":"SZk1n6ASSQyT","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.figure(figsize=(10, 5))\n","plt.plot(losses[0], label = 'generator')\n","plt.plot(losses[1], label = 'discriminator')\n","plt.title('Loss of training the gennerator and discriminator')\n","plt.xlabel('loss')\n","plt.ylabel('process')\n","plt.legend()\n","plt.show()\n","\n","for i in range(CONFIG.EPOCHS + 1):\n","    grid_img = util.make_figure_grid(imgs[i], 8)\n","    plt.figure()\n","    plt.imshow(grid_img)\n","    plt.show()"],"execution_count":0,"outputs":[]}]}