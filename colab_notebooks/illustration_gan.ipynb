{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"illustration_gan.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"_iBazkTQQeoV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":199},"outputId":"ce9ceda8-9583-4569-dc0e-50f7b362fb1c","executionInfo":{"status":"ok","timestamp":1554632471376,"user_tz":-480,"elapsed":27127,"user":{"displayName":"陈乐恒","photoUrl":"","userId":"14095346992415385481"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!nvcc --version"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2018 NVIDIA Corporation\n","Built on Sat_Aug_25_21:08:01_CDT_2018\n","Cuda compilation tools, release 10.0, V10.0.130\n"],"name":"stdout"}]},{"metadata":{"id":"AaFJYRlGQt_-","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":77},"outputId":"1bfb3a64-0b8a-4ac9-cb51-971781cd8d93","executionInfo":{"status":"ok","timestamp":1554632499881,"user_tz":-480,"elapsed":6845,"user":{"displayName":"陈乐恒","photoUrl":"","userId":"14095346992415385481"}}},"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-ec513aca-c966-47d5-9bbc-ef43816e32a6\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-ec513aca-c966-47d5-9bbc-ef43816e32a6\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving custom_layers.py to custom_layers.py\n"],"name":"stdout"}]},{"metadata":{"id":"05DwPf8jQywg","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","import util\n","import dataset as dset\n","from dataset import pokemonDataset\n","from custom_layers import bilinear_upsample_deconv2d"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YRRb6FjJRAew","colab_type":"code","colab":{}},"cell_type":"code","source":["class auxiliary_fc_net(nn.Module):\n","    def __init__(self, dim_noise, dim_output_img, num_reduce_half, num_filter):\n","        super(auxiliary_fc_net, self).__init__()\n","\n","        fc_size = 1024\n","        dim_feature_map = dim_output_img / (2 ** num_reduce_half)\n","        self.dim_imput = int((dim_feature_map ** 2) * num_filter)\n","        self.fc1 = nn.Linear(self.dim_imput, fc_size)\n","        self.fc2 = nn.Linear(fc_size, fc_size)\n","        self.fc3 = nn.Linear(fc_size, fc_size)\n","        self.fc4 = nn.Linear(fc_size, dim_noise)\n","\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.relu2 = nn.ReLU(inplace=True)\n","        self.relu3 = nn.ReLU(inplace=True)\n","        self.relu4 = nn.ReLU(inplace=True)\n","    \n","    def forward(self, x):\n","        x = x.view(-1, self.dim_imput)\n","        x = self.relu1(self.fc1(x))\n","        x = self.relu2(self.fc2(x))\n","        x = self.relu3(self.fc3(x))\n","        x = self.relu4(self.fc4(x))\n","        return x\n","\n","class generator_fc(nn.Module):\n","    def __init__(self, dim_noise, dim_output_img, num_reduce_half, num_filter):\n","        super(generator_fc, self).__init__()\n","\n","        fc_size = 1024\n","        dim_feature_map = int(dim_output_img / (2 ** num_reduce_half))\n","        self.reshape_params = [-1, num_filter, dim_feature_map, dim_feature_map]\n","        self.fc1 = nn.Linear(dim_noise, fc_size)\n","        self.fc2 = nn.Linear(fc_size, fc_size)\n","        self.fc3 = nn.Linear(fc_size, fc_size)\n","        self.fc4 = nn.Linear(fc_size, int((dim_feature_map ** 2) * num_filter))\n","\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.relu2 = nn.ReLU(inplace=True)\n","        self.relu3 = nn.ReLU(inplace=True)\n","        self.relu4 = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        x = self.relu1(self.fc1(x))\n","        x = self.relu2(self.fc2(x))\n","        x = self.relu3(self.fc3(x))\n","        x = self.relu4(self.fc4(x))\n","        x = x.view(self.reshape_params)\n","        return x\n","\n","class generator_convt(nn.Module):\n","\n","    def __init__(self, input_filters, dim_output_img=64, n_channel=3):\n","        super(generator_convt, self).__init__()\n","\n","        inplace = True\n","        # init_kernel_sise = int(dim_output_img / (2 ** 4))\n","        \n","        # self.bilinear1 = nn.Upsample(scale_factor=2, mode='bilinear')\n","        # self.conv1 = nn.Conv2d(input_filters, dim_output_img * 8, 5, 1, 2)\n","        self.bilinear_deconv1 = bilinear_upsample_deconv2d(2, input_filters, dim_output_img * 8, 5, 1, 2)\n","        self.batchnorm1 = nn.BatchNorm2d(dim_output_img*8)\n","        self.relu1 = nn.ReLU(inplace=inplace)\n","\n","        self.bilinear_deconv2 = bilinear_upsample_deconv2d(2, dim_output_img * 8, dim_output_img * 4, 5, 1, 2)\n","        self.batchnorm2 = nn.BatchNorm2d(dim_output_img*4)\n","        self.relu2 = nn.ReLU(inplace=inplace)\n","\n","        self.bilinear_deconv3 = bilinear_upsample_deconv2d(2, dim_output_img * 4, dim_output_img * 2, 5, 1, 2)\n","        self.batchnorm3 = nn.BatchNorm2d(dim_output_img*2)\n","        self.relu3 = nn.ReLU(inplace=inplace)\n","\n","        self.bilinear_deconv4 = bilinear_upsample_deconv2d(2, dim_output_img * 2, dim_output_img, 5, 1, 2)\n","        self.batchnorm4 = nn.BatchNorm2d(dim_output_img)\n","        self.relu4 = nn.ReLU(inplace=inplace)\n","\n","\n","        self.conv = nn.Conv2d(dim_output_img, n_channel, 5, 1, 2, bias=False)\n","        self.tanh = nn.Tanh()\n","\n","    def forward(self, x):\n","        x = self.batchnorm1(self.bilinear_deconv1(x))\n","        x = self.relu1(x)\n","        x = self.batchnorm2(self.bilinear_deconv2(x))\n","        x = self.relu2(x)\n","        x = self.batchnorm3(self.bilinear_deconv3(x))\n","        x = self.relu3(x)\n","        x = self.batchnorm4(self.bilinear_deconv4(x))\n","        x = self.relu4(x)\n","        x = self.tanh(self.conv(x))\n","        print('generator')\n","        print(x.size(2))\n","        return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kyiwWzPYRHUo","colab_type":"code","colab":{}},"cell_type":"code","source":["class generator(nn.Module):\n","\n","    def __init__(self, dim_noise=100, dim_output_img=64, n_channel=3):\n","        super(generator, self).__init__()\n","        num_filter = dim_output_img * 16\n","        num_reduce_half = 4\n","        self.fc = generator_fc(dim_noise, dim_output_img, num_reduce_half, num_filter)\n","        self.convt = generator_convt(num_filter, dim_output_img, n_channel)\n","        self.auxiliary = auxiliary_fc_net(dim_noise, dim_output_img, num_reduce_half, num_filter)\n","\n","    def forward(self, x):\n","        x_fc = self.fc(x)\n","        x_data = self.convt(x_fc)\n","        x_id = self.auxiliary(x_fc)\n","\n","        return x_data, x_id"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HK89XHtyfVeS","colab_type":"code","colab":{}},"cell_type":"code","source":["class minibatch_discrimination(nn.Module):\n","    def __init__(self, dim_input_feature, dim_output_feature, c):\n","        super(minibatch_discrimination, self).__init__()\n","        self.input_feture = dim_input_feature\n","        self.output_feature = dim_input_feature\n","        self.output_feature = dim_output_feature\n","        self.c = c\n","        self.weight = nn.Parameter(torch.empty(self.input_feture, self.output_feature * self.c))\n","        \n","    def forward(self, x):\n","        broadcast_mat = self.weight.view(self.input_feture, -1)\n","        x = x.view(-1, self.input_feture)\n","        mat = torch.mm(x, self.weight)\n","        mat = mat.view(-1, self.output_feature, self.c)\n","\n","        mat = mat.unsqueeze(0)\n","        mat_T = mat.permute(1, 0, 2, 3)\n","        output = torch.exp(-torch.abs(mat - mat_T).sum(3))\n","        output = output.sum(0)\n","\n","        x = torch.cat([x, output], 1)\n","        return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7_D3lpX7RNlj","colab_type":"code","colab":{}},"cell_type":"code","source":["class discriminator(nn.Module):\n","\n","    def __init__(self, dim_input_img=64, n_channel = 3):\n","        super(discriminator, self).__init__()\n","\n","        slope = 0.2\n","        inplace = True\n","        proba = 0.5\n","        \n","        self.conv1 = nn.Conv2d(n_channel, dim_input_img, 5, 1, 2, bias=False)\n","        self.lrelu1 = nn.LeakyReLU(negative_slope=slope, inplace=True)\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        self.do2 = nn.Dropout(p=proba, inplace=inplace)\n","        self.conv2 = nn.Conv2d(dim_input_img, dim_input_img * 2, 5, 1, 2, bias=False)\n","        self.batchnorm2 = nn.BatchNorm2d(int(dim_input_img * 2 / 2)) # maxpool need to /2\n","        self.lrelu2 = nn.LeakyReLU(negative_slope=slope, inplace=True)\n","        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n"," \n","        self.do3 = nn.Dropout(p=proba, inplace=inplace)\n","        self.conv3 = nn.Conv2d(dim_input_img * 2, dim_input_img * 4, 5, 1, 2, bias=False)\n","        self.batchnorm3 = nn.BatchNorm2d(int(dim_input_img * 4 / 2))\n","        self.lrelu3 = nn.LeakyReLU(negative_slope=slope, inplace=True)\n","        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n"," \n","        self.do4 = nn.Dropout(p=proba, inplace=inplace)\n","        self.conv4 = nn.Conv2d(dim_input_img * 4, dim_input_img * 8, 5, 1, 2, bias=False)\n","        self.batchnorm4 = nn.BatchNorm2d(int(dim_input_img * 8 / 2))\n","        self.lrelu4 = nn.LeakyReLU(negative_slope=slope, inplace=True)\n","        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","        dim_output_feature = 100\n","        dim_c = 25\n","        dim_feature_map = int(dim_input_img / (2 ** 4))\n","        # assert dim_feature_map == 4\n","\n","        self.flatten_size = dim_input_img * 8 * (dim_feature_map ** 2)\n","        self.miniDis = minibatch_discrimination(self.flatten_size, dim_output_feature, dim_c)\n","\n","        fc_size = 1024\n","\n","        self.fc1 = nn.Linear(self.flatten_size, fc_size)\n","        self.lrelu_fc1 = nn.LeakyReLU(negative_slope=slope, inplace=inplace)\n","        self.fc2 = nn.Linear(fc_size, fc_size)\n","        self.lrelu_fc2 = nn.LeakyReLU(negative_slope=slope, inplace=inplace)\n","        self.fc3 = nn.Linear(fc_size, fc_size)\n","        self.lrelu_fc3 = nn.LeakyReLU(negative_slope=slope, inplace=inplace)\n","\n","        self.fc4 = nn.Linear(fc_size + self.flatten_size + dim_output_feature, 1)\n","        self.lrelu_fc4 = nn.LeakyReLU(negative_slope=slope)\n"," \n","\n","    def forward(self, x):\n","        x = self.maxpool1(self.lrelu1(self.conv1(x)))\n","        x = self.conv2(self.batchnorm2(self.do2(x)))\n","        x = self.maxpool2(self.lrelu2(x))\n","        x = self.conv3(self.batchnorm3(self.do3(x)))\n","        x = self.maxpool3(self.lrelu3(x))\n","        x = self.conv4(self.batchnorm4(self.do4(x)))\n","        x = self.maxpool4(self.lrelu4(x))\n","\n","        x = x.view(-1, self.flatten_size)\n","        x_mini_dis = self.miniDis(x)\n","\n","        x = self.lrelu_fc1(self.fc1(x))\n","        x = self.lrelu_fc2(self.fc2(x))\n","        x = self.lrelu_fc3(self.fc3(x))\n","\n","        x = torch.cat([x, x_mini_dis], 1)\n","        x = self.lrelu_fc4(self.fc4(x))\n","\n","        return x"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m-MtTqBPRknN","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_base(epochs, batch_size, dim_noise, device, dataset, generator, discriminator, loss, loss_auxiliary, optimizer_gen, optimizer_dis, filepath=None):\n","    # load the data\n","    worker = 2\n","    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=worker)\n","    \n","    # create the list to store each loss\n","    loss_list, score_list, img_list = [], [], []\n","    num_fixed_ns_img = 64\n","    fixed_noise = torch.randn(num_fixed_ns_img, dim_noise, 1, 1, device=device)\n","\n","    # start iterating the epoch\n","    for e in range(epochs):\n","        loss_dis, loss_gen, score_dis_real, score_dis_fake, score_gen = 0, 0, 0, 0, 0\n","\n","        for i, data in enumerate(dataloader):\n","            b_size = batch_size\n","            if len(data[0]) < batch_size:\n","                b_size = len(data[0])\n","            # ---------------------------\n","            # 1. Train the discriminator\n","            # ---------------------------\n","            # generate noise samples from the generator\n","            batch_noise = torch.randn(b_size, dim_noise, device=device)\n","            fake_data, noise_id = generator(batch_noise)\n","\n","            # start to train the discriminator\n","            discriminator.zero_grad()\n","            # calculate the loss of the noise samples, which assigns the same label 0\n","            # for all the samples, and get the single output(marks) from the discriminator\n","            output = discriminator(fake_data.detach()).view(-1) # use .detach() to stop the requirement of gradient\n","            label = torch.full((b_size,), 0, device=device)\n","            loss_d_ns = loss(output, label)\n","            loss_d_ns.backward()\n","            score_dis_fake = output.mean().item()\n","            \n","            # calculate the loss of the real samples and assigns label 1 to represent\n","            # all samples are true and get the single output(marks) from the discriminator\n","            read_data = data[0].to(device)\n","            output = discriminator(read_data).view(-1)\n","            label.fill_(1)\n","            loss_d_real = loss(output, label)\n","            loss_d_real.backward()\n","            score_dis_real = output.mean().item()\n","\n","            loss_d = loss_d_ns + loss_d_real\n","            loss_dis = loss_d.item()\n","            optimizer_dis.step()\n","\n","            # ---------------------------\n","            # 2. Train the generator\n","            # ---------------------------\n","            # Feed the noise samplea to the discriminator agian to geit the accurate scores\n","            # after training the discriminator, and assign label 1 not to see the noise as\n","            # real label but to let the loss function to be correct and do correct back propogation\n","            generator.zero_grad()            \n","            # batch_noise = Func.torch.randn(b_size, dim_noise)\n","            # fake_data = generator(batch_noise)\n","            output = discriminator(fake_data).view(-1)\n","            loss_main = loss(output, label)\n","            loss_aux = loss_auxiliary(noise_id, batch_noise)\n","            loss_g = loss_main + loss_aux\n","            loss_g.backward()\n","            score_gen = output.mean().item()\n","            loss_gen = loss_g.item()\n","            optimizer_gen.step()\n","\n","\n","            # print information to the console\n","            # print information 5 times in a epoch\n","            num2print = 30\n","            if (i + 1) % num2print == 0:\n","                print('epoch: %d, iter: %d, loss_D: %.4f, loss_G: %.4f;\\t Scores: train D: D(x): %.4f, D(G(z)): %.4f train G: D(G(z))： %.4f'\n","                        % (e, (i + 1), loss_dis, loss_gen, score_dis_real, score_dis_fake, score_gen))           \n","                \n","                # store the final loss for D and G for a specific time interval of a whole epoch\n","                loss_list.append([loss_dis, loss_gen])\n","                # store the final score from D for noise and real samples for a specific time imterval on current epoch\n","                score_list.append([score_dis_fake, score_dis_real, score_gen])\n","\n","        loss_list.append([loss_dis, loss_gen])\n","        score_list.append([score_dis_fake, score_dis_real, score_gen])\n","        # store the image that the generator create for each epoch\n","        test_img = generator(fixed_noise).detach().cpu()\n","        img_list.append(test_img.numpy())\n","\n","        # save the model\n","        if (e + 1) % 5 == 0:\n","            util.save_checkpoint(e, generator, discriminator, filepath)\n","    \n","    loss_list = list(map(list, zip(*loss_list)))\n","    score_list = list(map(list, zip(*score_list)))\n","        \n","    return generator, discriminator, loss_list, score_list, img_list"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Not6G17mRq0b","colab_type":"code","colab":{}},"cell_type":"code","source":["def build_gen_dis(config):\n","    net_gen = generator(config.DIM_NOISE, config.DIM_IMG).to(config.DEVICE)\n","    net_gen.apply(init_weight)\n","    print('finish initialization')\n","    net_dis = discriminator(config.DIM_IMG).to(config.DEVICE)\n","\n","    net_dis.apply(init_weight)\n","    print('finish initialization')\n","\n","    return net_gen, net_dis\n","\n","def train(dataset, net_gen, net_dis, config):\n","\n","    # config = config.config_illustration_gan\n","    # net_gen = generator(config.DIM_NOISE, config.DIM_IMG).to(config.DEVICE)\n","    # net_dis = discriminator(config.DIM_IMG).to(config.DEVICE)\n","\n","    loss_main = nn.BCEWithLogitsLoss()\n","    loss_aux = nn.MSELoss()\n","\n","    optim_gen = optim.Adam(net_gen.parameters(), lr=config.LEARNING_RATE, betas=(config.MOMENTUM, 0.99))\n","    optim_dis = optim.Adam(net_dis.parameters(), lr=config.LEARNING_RATE, betas=(config.MOMENTUM, 0.99))\n","\n","    net_gen, net_dis, losses, _, imgs = train_base(config.EPOCHS, config.BATCH_SIZE, config.DIM_NOISE, config.DEVICE,\n","                                                    dataset, net_gen, net_dis, loss_main, loss_aux, optim_gen, optim_dis, config.PATH_MODEL)\n","    \n","    return net_gen, net_dis, losses, imgs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3geqdQJoRW6N","colab_type":"code","colab":{}},"cell_type":"code","source":["def init_weight(layer):\n","    std = 0.02\n","    if type(layer) == nn.ConvTranspose2d:\n","        nn.init.normal_(layer.weight.data, mean=0, std=std)\n","    elif type(layer) == nn.Conv2d:\n","        nn.init.normal_(layer.weight.data, mean=0, std=std)\n","    elif type(layer) == nn.Linear:\n","        nn.init.normal_(layer.weight.data, mean=0, std=std)\n","        nn.init.normal_(layer.bias.data, mean=0, std=std)\n","    elif type(layer) == minibatch_discrimination:\n","         nn.init.normal_(layer.weight.data, mean=0, std=std)\n","    elif type(layer) == nn.BatchNorm2d:\n","        nn.init.normal_(layer.weight.data, mean=1, std=std)\n","        nn.init.constant_(layer.bias.data, 0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CXQbEoAtR5zG","colab_type":"code","colab":{}},"cell_type":"code","source":["PATH_IMAGE = '/content/gdrive/My Drive/data/image_128'\n","PATH_TAG = '/content/gdrive/My Drive/data/tags'\n","ARTWORK_TYPE = os.listdir(PATH_IMAGE)\n","IS_ADD_I2V_TAG = False\n","\n","class config_illustration_gan():\n","    PATH_MODEL = '/content/gdrive/My Drive/data/illust_gan_64.pth'\n","    IS_ADD_I2V_TAG = False\n","    BATCH_SIZE = 64\n","    DIM_IMG = 128\n","    DIM_NOISE = 100\n","    LEARNING_RATE = 0.0002\n","    MOMENTUM = 0.5\n","    EPOCHS = 100\n","    INIT = True\n","    IMPORT_IDX_EPOCH = EPOCHS\n","    DEVICE = torch.device(\"cuda:0\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"W7jPyXSLSHLJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":2299},"outputId":"eb81ecfe-4303-4e20-944a-7ed6ce530b9d","executionInfo":{"status":"error","timestamp":1554639970734,"user_tz":-480,"elapsed":36485,"user":{"displayName":"陈乐恒","photoUrl":"","userId":"14095346992415385481"}}},"cell_type":"code","source":["# create the dataset\n","dataset = pokemonDataset(PATH_IMAGE, PATH_TAG, ['ken sugimori'], IS_ADD_I2V_TAG)\n","\n","\n","# mean, std = dset.get_channel_mean_std(dataset, DIM_IMG)\n","# mean = [220.43362509, 217.50907014, 212.78514176]\n","# std = [71.7985852,  73.64374336, 78.23258064]\n","\n","transform=transforms.Compose([dset.ToDoubleTensor(), dset.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n","dataset.set_transform(transform)\n","\n","CONFIG = config_illustration_gan\n","net_gen, net_dis = build_gen_dis(CONFIG)\n","print(net_gen)\n","print(net_dis)\n","net_gen, net_dis, losses, imgs = train(dataset, net_gen, net_dis, CONFIG)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["finish initialization\n","finish initialization\n","generator(\n","  (fc): generator_fc(\n","    (fc1): Linear(in_features=100, out_features=1024, bias=True)\n","    (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","    (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n","    (fc4): Linear(in_features=1024, out_features=131072, bias=True)\n","    (relu1): ReLU(inplace)\n","    (relu2): ReLU(inplace)\n","    (relu3): ReLU(inplace)\n","    (relu4): ReLU(inplace)\n","  )\n","  (convt): generator_convt(\n","    (bilinear_deconv1): bilinear_upsample_deconv2d(\n","      (bilinear): Upsample(scale_factor=2, mode=bilinear)\n","      (conv): Conv2d(2048, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    )\n","    (batchnorm1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu1): ReLU(inplace)\n","    (bilinear_deconv2): bilinear_upsample_deconv2d(\n","      (bilinear): Upsample(scale_factor=2, mode=bilinear)\n","      (conv): Conv2d(1024, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    )\n","    (batchnorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu2): ReLU(inplace)\n","    (bilinear_deconv3): bilinear_upsample_deconv2d(\n","      (bilinear): Upsample(scale_factor=2, mode=bilinear)\n","      (conv): Conv2d(512, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    )\n","    (batchnorm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu3): ReLU(inplace)\n","    (bilinear_deconv4): bilinear_upsample_deconv2d(\n","      (bilinear): Upsample(scale_factor=2, mode=bilinear)\n","      (conv): Conv2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    )\n","    (batchnorm4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu4): ReLU(inplace)\n","    (conv): Conv2d(128, 3, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","    (tanh): Tanh()\n","  )\n","  (auxiliary): auxiliary_fc_net(\n","    (fc1): Linear(in_features=131072, out_features=1024, bias=True)\n","    (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","    (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n","    (fc4): Linear(in_features=1024, out_features=100, bias=True)\n","    (relu1): ReLU(inplace)\n","    (relu2): ReLU(inplace)\n","    (relu3): ReLU(inplace)\n","    (relu4): ReLU(inplace)\n","  )\n",")\n","discriminator(\n","  (conv1): Conv2d(3, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","  (lrelu1): LeakyReLU(negative_slope=0.2, inplace)\n","  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (do2): Dropout(p=0.5, inplace)\n","  (conv2): Conv2d(128, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","  (batchnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (lrelu2): LeakyReLU(negative_slope=0.2, inplace)\n","  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (do3): Dropout(p=0.5, inplace)\n","  (conv3): Conv2d(256, 512, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","  (batchnorm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (lrelu3): LeakyReLU(negative_slope=0.2, inplace)\n","  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (do4): Dropout(p=0.5, inplace)\n","  (conv4): Conv2d(512, 1024, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n","  (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (lrelu4): LeakyReLU(negative_slope=0.2, inplace)\n","  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (miniDis): minibatch_discrimination()\n","  (fc1): Linear(in_features=65536, out_features=1024, bias=True)\n","  (lrelu_fc1): LeakyReLU(negative_slope=0.2, inplace)\n","  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","  (lrelu_fc2): LeakyReLU(negative_slope=0.2, inplace)\n","  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n","  (lrelu_fc3): LeakyReLU(negative_slope=0.2, inplace)\n","  (fc4): Linear(in_features=66660, out_features=1, bias=True)\n","  (lrelu_fc4): LeakyReLU(negative_slope=0.2)\n",")\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2423: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n"],"name":"stderr"},{"output_type":"stream","text":["generator\n","128\n","64\n","64\n","32\n","32\n","16\n","16\n","8\n","64\n","64\n","32\n","32\n","16\n","16\n","8\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-36e5257a18ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_dis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mnet_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_dis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_dis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-7-c9dbf8854137>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, net_gen, net_dis, config)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     net_gen, net_dis, losses, _, imgs = train_base(config.EPOCHS, config.BATCH_SIZE, config.DIM_NOISE, config.DEVICE,\n\u001b[0;32m---> 25\u001b[0;31m                                                     dataset, net_gen, net_dis, loss_main, loss_aux, optim_gen, optim_dis, config.PATH_MODEL)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnet_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_dis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-5ee2738d8fd3>\u001b[0m in \u001b[0;36mtrain_base\u001b[0;34m(epochs, batch_size, dim_noise, device, dataset, generator, discriminator, loss, loss_auxiliary, optimizer_gen, optimizer_dis, filepath)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mloss_d_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloss_d_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mscore_dis_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_d_ns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_d_real\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"id":"SZk1n6ASSQyT","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.figure(figsize=(20, 10))\n","plt.plot(losses[0], label = 'generator')\n","plt.plot(losses[1], label = 'discriminator')\n","plt.title('Loss of training the gennerator and discriminator')\n","plt.xlabel('loss')\n","plt.ylabel('process')\n","plt.legend()\n","plt.show()\n","\n","grid_img = util.make_figure_grid(imgs[0], 8)\n","plt.figure()\n","plt.imshow(grid_img)\n","plt.show()"],"execution_count":0,"outputs":[]}]}